{"/home/travis/build/npmtest/node-npmtest-ava/test.js":"/* istanbul instrument in package npmtest_ava */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireExampleJsFromReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        local.testCase_browser_nullCase = local.testCase_browser_nullCase || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test browsers's null-case handling-behavior-behavior\n         */\n            onError(null, options);\n        };\n\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-ava/lib.npmtest_ava.js":"/* istanbul instrument in package npmtest_ava */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_ava = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_ava = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-ava/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-ava && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_ava */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_ava\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_ava.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        // bug-workaround - long $npm_package_buildCustomOrg\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.npmtest_ava.rollup.js'] =\n            local.assetsDict['/assets.npmtest_ava.rollup.js'] ||\n            local.fs.readFileSync(\n                local.npmtest_ava.__dirname + '/lib.npmtest_ava.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        /* jslint-ignore-end */\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/index.js":"'use strict';\n\n// Ensure the same AVA install is loaded by the test file as by the test worker\nif (process.env.AVA_PATH && process.env.AVA_PATH !== __dirname) {\n\tmodule.exports = require(process.env.AVA_PATH); // eslint-disable-line import/no-dynamic-require\n} else {\n\tmodule.exports = require('./lib/main');\n}\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/main.js":"'use strict';\nconst worker = require('./test-worker');\nconst adapter = require('./process-adapter');\nconst serializeError = require('./serialize-error');\nconst globals = require('./globals');\nconst Runner = require('./runner');\n\nconst opts = globals.options;\nconst runner = new Runner({\n\tbail: opts.failFast,\n\tfailWithoutAssertions: opts.failWithoutAssertions,\n\tfile: opts.file,\n\tmatch: opts.match,\n\tserial: opts.serial,\n\tupdateSnapshots: opts.updateSnapshots\n});\n\nworker.setRunner(runner);\n\n// If fail-fast is enabled, use this variable to detect\n// that no more tests should be logged\nlet isFailed = false;\n\nError.stackTraceLimit = Infinity;\n\nfunction test(props) {\n\tif (isFailed) {\n\t\treturn;\n\t}\n\n\tconst hasError = typeof props.error !== 'undefined';\n\n\t// Don't display anything if it's a passed hook\n\tif (!hasError && props.type !== 'test') {\n\t\treturn;\n\t}\n\n\tif (hasError) {\n\t\tprops.error = serializeError(props.error);\n\t} else {\n\t\tprops.error = null;\n\t}\n\n\tadapter.send('test', props);\n\n\tif (hasError && opts.failFast) {\n\t\tisFailed = true;\n\t\texit();\n\t}\n}\n\nfunction exit() {\n\t// Reference the IPC channel now that tests have finished running.\n\tadapter.ipcChannel.ref();\n\n\tconst stats = runner.buildStats();\n\tadapter.send('results', {stats});\n}\n\nglobals.setImmediate(() => {\n\tconst hasExclusive = runner.tests.hasExclusive;\n\tconst numberOfTests = runner.tests.testCount;\n\n\tif (numberOfTests === 0) {\n\t\tadapter.send('no-tests', {avaRequired: true});\n\t\treturn;\n\t}\n\n\tadapter.send('stats', {\n\t\ttestCount: numberOfTests,\n\t\thasExclusive\n\t});\n\n\trunner.on('test', test);\n\n\tprocess.on('ava-run', options => {\n\t\t// Unreference the IPC channel. This stops it from keeping the event loop\n\t\t// busy, which means the `beforeExit` event can be used to detect when tests\n\t\t// stall.\n\t\tadapter.ipcChannel.unref();\n\n\t\trunner.run(options)\n\t\t\t.then(() => {\n\t\t\t\trunner.saveSnapshotState();\n\n\t\t\t\treturn exit();\n\t\t\t})\n\t\t\t.catch(err => {\n\t\t\t\tprocess.emit('uncaughtException', err);\n\t\t\t});\n\t});\n\n\tprocess.on('ava-init-exit', () => {\n\t\texit();\n\t});\n});\n\nmodule.exports = runner.chain;\n\n// TypeScript imports the `default` property for\n// an ES2015 default import (`import test from 'ava'`)\n// See: https://github.com/Microsoft/TypeScript/issues/2242#issuecomment-83694181\nmodule.exports.default = runner.chain;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/test-worker.js":"'use strict';\n\n// Check if the test is being run without AVA cli\n{\n\t/* eslint-disable import/order */\n\tconst path = require('path');\n\tconst chalk = require('chalk');\n\n\tconst isForked = typeof process.send === 'function';\n\tif (!isForked) {\n\t\tconst fp = path.relative('.', process.argv[1]);\n\n\t\tconsole.log();\n\t\tconsole.error('Test files must be run with the AVA CLI:\\n\\n    ' + chalk.grey.dim('$') + ' ' + chalk.cyan('ava ' + fp) + '\\n');\n\n\t\tprocess.exit(1); // eslint-disable-line unicorn/no-process-exit\n\t}\n}\n\n/* eslint-enable import/order */\nconst Bluebird = require('bluebird');\nconst currentlyUnhandled = require('currently-unhandled')();\nconst isObj = require('is-obj');\nconst adapter = require('./process-adapter');\nconst globals = require('./globals');\nconst serializeError = require('./serialize-error');\n\nconst opts = adapter.opts;\nconst testPath = opts.file;\nglobals.options = opts;\n\n// Bluebird specific\nBluebird.longStackTraces();\n\n(opts.require || []).forEach(require);\n\nadapter.installSourceMapSupport();\nadapter.installPrecompilerHook();\n\nconst dependencies = [];\nadapter.installDependencyTracking(dependencies, testPath);\n\n// Set when main.js is required (since test files should have `require('ava')`).\nlet runner = null;\nexports.setRunner = newRunner => {\n\trunner = newRunner;\n};\n\nrequire(testPath); // eslint-disable-line import/no-dynamic-require\n\n// If AVA was not required, show an error\nif (!runner) {\n\tadapter.send('no-tests', {avaRequired: false});\n}\n\nfunction attributeLeakedError(err) {\n\tif (!runner) {\n\t\treturn false;\n\t}\n\n\treturn runner.attributeLeakedError(err);\n}\n\nconst attributedRejections = new Set();\nprocess.on('unhandledRejection', (reason, promise) => {\n\tif (attributeLeakedError(reason)) {\n\t\tattributedRejections.add(promise);\n\t}\n});\n\nprocess.on('uncaughtException', exception => {\n\tif (attributeLeakedError(exception)) {\n\t\treturn;\n\t}\n\n\tlet serialized;\n\ttry {\n\t\tserialized = serializeError(exception);\n\t} catch (ignore) { // eslint-disable-line unicorn/catch-error-name\n\t\t// Avoid using serializeError\n\t\tconst err = new Error('Failed to serialize uncaught exception');\n\t\tserialized = {\n\t\t\tavaAssertionError: false,\n\t\t\tname: err.name,\n\t\t\tmessage: err.message,\n\t\t\tstack: err.stack\n\t\t};\n\t}\n\n\t// Ensure the IPC channel is refereced. The uncaught exception will kick off\n\t// the teardown sequence, for which the messages must be received.\n\tadapter.ipcChannel.ref();\n\n\tadapter.send('uncaughtException', {exception: serialized});\n});\n\nlet tearingDown = false;\nprocess.on('ava-teardown', () => {\n\t// AVA-teardown can be sent more than once\n\tif (tearingDown) {\n\t\treturn;\n\t}\n\ttearingDown = true;\n\n\tlet rejections = currentlyUnhandled()\n\t\t.filter(rejection => !attributedRejections.has(rejection.promise));\n\n\tif (rejections.length > 0) {\n\t\trejections = rejections.map(rejection => {\n\t\t\tlet reason = rejection.reason;\n\t\t\tif (!isObj(reason) || typeof reason.message !== 'string') {\n\t\t\t\treason = {\n\t\t\t\t\tmessage: String(reason)\n\t\t\t\t};\n\t\t\t}\n\t\t\treturn serializeError(reason);\n\t\t});\n\n\t\tadapter.send('unhandledRejections', {rejections});\n\t}\n\n\t// Include dependencies in the final teardown message. This ensures the full\n\t// set of dependencies is included no matter how the process exits, unless\n\t// it flat out crashes.\n\tadapter.send('teardown', {dependencies});\n});\n\nprocess.on('ava-exit', () => {\n\tprocess.exit(0); // eslint-disable-line xo/no-process-exit\n});\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/process-adapter.js":"'use strict';\nconst fs = require('fs');\nconst path = require('path');\nconst debug = require('debug')('ava');\nconst sourceMapSupport = require('source-map-support');\nconst installPrecompiler = require('require-precompiled');\n\n// Parse and re-emit AVA messages\nprocess.on('message', message => {\n\tif (!message.ava) {\n\t\treturn;\n\t}\n\n\tprocess.emit(message.name, message.data);\n});\n\nexports.send = (name, data) => {\n\tprocess.send({\n\t\tname: `ava-${name}`,\n\t\tdata,\n\t\tava: true\n\t});\n};\n\n// `process.channel` was added in Node.js 7.1.0, but the channel was available\n// through an undocumented API as `process._channel`.\nexports.ipcChannel = process.channel || process._channel;\n\nconst opts = JSON.parse(process.argv[2]);\nexports.opts = opts;\n\n// Fake TTY support\nif (opts.tty) {\n\tprocess.stdout.isTTY = true;\n\tprocess.stdout.columns = opts.tty.columns || 80;\n\tprocess.stdout.rows = opts.tty.rows;\n\n\tconst tty = require('tty');\n\tconst isatty = tty.isatty;\n\n\ttty.isatty = function (fd) {\n\t\tif (fd === 1 || fd === process.stdout) {\n\t\t\treturn true;\n\t\t}\n\n\t\treturn isatty(fd);\n\t};\n}\n\nif (debug.enabled) {\n\t// Forward the `time-require` `--sorted` flag.\n\t// Intended for internal optimization tests only.\n\tif (opts._sorted) {\n\t\tprocess.argv.push('--sorted');\n\t}\n\n\trequire('time-require'); // eslint-disable-line import/no-unassigned-import\n}\n\nconst sourceMapCache = new Map();\nconst cacheDir = opts.cacheDir;\n\nexports.installSourceMapSupport = () => {\n\tsourceMapSupport.install({\n\t\tenvironment: 'node',\n\t\thandleUncaughtExceptions: false,\n\t\tretrieveSourceMap(source) {\n\t\t\tif (sourceMapCache.has(source)) {\n\t\t\t\treturn {\n\t\t\t\t\turl: source,\n\t\t\t\t\tmap: fs.readFileSync(sourceMapCache.get(source), 'utf8')\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\t});\n};\n\nexports.installPrecompilerHook = () => {\n\tinstallPrecompiler(filename => {\n\t\tconst precompiled = opts.precompiled[filename];\n\n\t\tif (precompiled) {\n\t\t\tsourceMapCache.set(filename, path.join(cacheDir, `${precompiled}.js.map`));\n\t\t\treturn fs.readFileSync(path.join(cacheDir, `${precompiled}.js`), 'utf8');\n\t\t}\n\n\t\treturn null;\n\t});\n};\n\nexports.installDependencyTracking = (dependencies, testPath) => {\n\tObject.keys(require.extensions).forEach(ext => {\n\t\tconst wrappedHandler = require.extensions[ext];\n\n\t\trequire.extensions[ext] = (module, filename) => {\n\t\t\tif (filename !== testPath) {\n\t\t\t\tdependencies.push(filename);\n\t\t\t}\n\n\t\t\twrappedHandler(module, filename);\n\t\t};\n\t});\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/api.js":"'use strict';\nconst EventEmitter = require('events');\nconst path = require('path');\nconst fs = require('fs');\nconst commonPathPrefix = require('common-path-prefix');\nconst uniqueTempDir = require('unique-temp-dir');\nconst findCacheDir = require('find-cache-dir');\nconst resolveCwd = require('resolve-cwd');\nconst debounce = require('lodash.debounce');\nconst autoBind = require('auto-bind');\nconst Promise = require('bluebird');\nconst getPort = require('get-port');\nconst arrify = require('arrify');\nconst ms = require('ms');\nconst babelConfigHelper = require('./lib/babel-config');\nconst CachingPrecompiler = require('./lib/caching-precompiler');\nconst RunStatus = require('./lib/run-status');\nconst AvaError = require('./lib/ava-error');\nconst AvaFiles = require('./lib/ava-files');\nconst fork = require('./lib/fork');\n\nfunction resolveModules(modules) {\n\treturn arrify(modules).map(name => {\n\t\tconst modulePath = resolveCwd(name);\n\n\t\tif (modulePath === null) {\n\t\t\tthrow new Error(`Could not resolve required module '${name}'`);\n\t\t}\n\n\t\treturn modulePath;\n\t});\n}\n\nfunction getBlankResults() {\n\treturn {\n\t\tstats: {\n\t\t\tknownFailureCount: 0,\n\t\t\ttestCount: 0,\n\t\t\tpassCount: 0,\n\t\t\tskipCount: 0,\n\t\t\ttodoCount: 0,\n\t\t\tfailCount: 0\n\t\t},\n\t\ttests: []\n\t};\n}\n\nclass Api extends EventEmitter {\n\tconstructor(options) {\n\t\tsuper();\n\t\tautoBind(this);\n\n\t\tthis.options = Object.assign({match: []}, options);\n\t\tthis.options.require = resolveModules(this.options.require);\n\t}\n\t_runFile(file, runStatus, execArgv) {\n\t\tconst hash = this.precompiler.precompileFile(file);\n\t\tconst precompiled = Object.assign({}, this._precompiledHelpers);\n\t\tconst resolvedfpath = fs.realpathSync(file);\n\t\tprecompiled[resolvedfpath] = hash;\n\n\t\tconst options = Object.assign({}, this.options, {precompiled});\n\t\tconst emitter = fork(file, options, execArgv);\n\t\trunStatus.observeFork(emitter);\n\n\t\treturn emitter;\n\t}\n\trun(files, options) {\n\t\treturn new AvaFiles({cwd: this.options.resolveTestsFrom, files})\n\t\t\t.findTestFiles()\n\t\t\t.then(files => this._run(files, options));\n\t}\n\t_onTimeout(runStatus) {\n\t\tconst timeout = ms(this.options.timeout);\n\t\tconst err = new AvaError(`Exited because no new tests completed within the last ${timeout}ms of inactivity`);\n\t\tthis._handleError(runStatus, err);\n\t\trunStatus.emit('timeout');\n\t}\n\t_setupTimeout(runStatus) {\n\t\tconst timeout = ms(this.options.timeout);\n\n\t\trunStatus._restartTimer = debounce(() => {\n\t\t\tthis._onTimeout(runStatus);\n\t\t}, timeout);\n\n\t\trunStatus._restartTimer();\n\t\trunStatus.on('test', runStatus._restartTimer);\n\t}\n\t_cancelTimeout(runStatus) {\n\t\trunStatus._restartTimer.cancel();\n\t}\n\t_setupPrecompiler(files) {\n\t\tconst isCacheEnabled = this.options.cacheEnabled !== false;\n\t\tlet cacheDir = uniqueTempDir();\n\n\t\tif (isCacheEnabled) {\n\t\t\tconst foundDir = findCacheDir({\n\t\t\t\tname: 'ava',\n\t\t\t\tfiles\n\t\t\t});\n\t\t\tif (foundDir !== null) {\n\t\t\t\tcacheDir = foundDir;\n\t\t\t}\n\t\t}\n\n\t\tthis.options.cacheDir = cacheDir;\n\n\t\tconst isPowerAssertEnabled = this.options.powerAssert !== false;\n\t\treturn babelConfigHelper.build(this.options.projectDir, cacheDir, this.options.babelConfig, isPowerAssertEnabled)\n\t\t\t.then(result => {\n\t\t\t\tthis.precompiler = new CachingPrecompiler({\n\t\t\t\t\tpath: cacheDir,\n\t\t\t\t\tgetBabelOptions: result.getOptions,\n\t\t\t\t\tbabelCacheKeys: result.cacheKeys\n\t\t\t\t});\n\t\t\t});\n\t}\n\t_precompileHelpers() {\n\t\tthis._precompiledHelpers = {};\n\n\t\t// Assumes the tests only load helpers from within the `resolveTestsFrom`\n\t\t// directory. Without arguments this is the `projectDir`, else it's\n\t\t// `process.cwd()` which may be nested too deeply. This will be solved\n\t\t// as we implement RFC 001 and move helper compilation into the worker\n\t\t// processes, avoiding the need for precompilation.\n\t\treturn new AvaFiles({cwd: this.options.resolveTestsFrom})\n\t\t\t.findTestHelpers()\n\t\t\t.map(file => { // eslint-disable-line array-callback-return\n\t\t\t\tconst hash = this.precompiler.precompileFile(file);\n\t\t\t\tthis._precompiledHelpers[file] = hash;\n\t\t\t});\n\t}\n\t_run(files, options) {\n\t\toptions = options || {};\n\n\t\tconst runStatus = new RunStatus({\n\t\t\trunOnlyExclusive: options.runOnlyExclusive,\n\t\t\tprefixTitles: this.options.explicitTitles || files.length > 1,\n\t\t\tbase: path.relative(process.cwd(), commonPathPrefix(files)) + path.sep,\n\t\t\tfailFast: this.options.failFast\n\t\t});\n\n\t\tthis.emit('test-run', runStatus, files);\n\n\t\tif (files.length === 0) {\n\t\t\tconst err = new AvaError('Couldn\\'t find any files to test');\n\t\t\tthis._handleError(runStatus, err);\n\t\t\treturn Promise.resolve(runStatus);\n\t\t}\n\n\t\treturn this._setupPrecompiler(files)\n\t\t\t.then(() => this._precompileHelpers())\n\t\t\t.then(() => {\n\t\t\t\tif (this.options.timeout) {\n\t\t\t\t\tthis._setupTimeout(runStatus);\n\t\t\t\t}\n\n\t\t\t\tlet overwatch;\n\t\t\t\tif (this.options.concurrency > 0) {\n\t\t\t\t\tconst concurrency = this.options.serial ? 1 : this.options.concurrency;\n\t\t\t\t\toverwatch = this._runWithPool(files, runStatus, concurrency);\n\t\t\t\t} else {\n\t\t\t\t\t// _runWithoutPool exists to preserve legacy behavior, specifically around `.only`\n\t\t\t\t\toverwatch = this._runWithoutPool(files, runStatus);\n\t\t\t\t}\n\n\t\t\t\treturn overwatch;\n\t\t\t});\n\t}\n\t_computeForkExecArgs(files) {\n\t\tconst execArgv = this.options.testOnlyExecArgv || process.execArgv;\n\t\tlet debugArgIndex = -1;\n\n\t\t// --debug-brk is used in addition to --inspect to break on first line and wait\n\t\texecArgv.some((arg, index) => {\n\t\t\tconst isDebugArg = arg === '--inspect' || arg.indexOf('--inspect=') === 0;\n\t\t\tif (isDebugArg) {\n\t\t\t\tdebugArgIndex = index;\n\t\t\t}\n\n\t\t\treturn isDebugArg;\n\t\t});\n\n\t\tconst isInspect = debugArgIndex >= 0;\n\t\tif (!isInspect) {\n\t\t\texecArgv.some((arg, index) => {\n\t\t\t\tconst isDebugArg = arg === '--debug' || arg === '--debug-brk' || arg.indexOf('--debug-brk=') === 0 || arg.indexOf('--debug=') === 0;\n\t\t\t\tif (isDebugArg) {\n\t\t\t\t\tdebugArgIndex = index;\n\t\t\t\t}\n\n\t\t\t\treturn isDebugArg;\n\t\t\t});\n\t\t}\n\n\t\tif (debugArgIndex === -1) {\n\t\t\treturn Promise.resolve([]);\n\t\t}\n\n\t\treturn Promise\n\t\t\t.map(files, () => getPort())\n\t\t\t.map(port => {\n\t\t\t\tconst forkExecArgv = execArgv.slice();\n\t\t\t\tlet flagName = isInspect ? '--inspect' : '--debug';\n\t\t\t\tconst oldValue = forkExecArgv[debugArgIndex];\n\t\t\t\tif (oldValue.indexOf('brk') > 0) {\n\t\t\t\t\tflagName += '-brk';\n\t\t\t\t}\n\n\t\t\t\tforkExecArgv[debugArgIndex] = `${flagName}=${port}`;\n\n\t\t\t\treturn forkExecArgv;\n\t\t\t});\n\t}\n\t_handleError(runStatus, err) {\n\t\trunStatus.handleExceptions({\n\t\t\texception: err,\n\t\t\tfile: err.file ? path.relative(process.cwd(), err.file) : undefined\n\t\t});\n\t}\n\t_runWithoutPool(files, runStatus) {\n\t\tconst tests = [];\n\t\tlet execArgvList;\n\n\t\t// TODO: This should be cleared at the end of the run\n\t\trunStatus.on('timeout', () => {\n\t\t\ttests.forEach(fork => {\n\t\t\t\tfork.exit();\n\t\t\t});\n\t\t});\n\n\t\treturn this._computeForkExecArgs(files)\n\t\t\t.then(argvList => {\n\t\t\t\texecArgvList = argvList;\n\t\t\t})\n\t\t\t.return(files)\n\t\t\t.each((file, index) => {\n\t\t\t\treturn new Promise(resolve => {\n\t\t\t\t\tconst forkArgs = execArgvList[index];\n\t\t\t\t\tconst test = this._runFile(file, runStatus, forkArgs);\n\t\t\t\t\ttests.push(test);\n\t\t\t\t\ttest.on('stats', resolve);\n\t\t\t\t\ttest.catch(resolve);\n\t\t\t\t}).catch(err => {\n\t\t\t\t\terr.results = [];\n\t\t\t\t\terr.file = file;\n\t\t\t\t\treturn Promise.reject(err);\n\t\t\t\t});\n\t\t\t})\n\t\t\t.then(() => {\n\t\t\t\tif (this.options.match.length > 0 && !runStatus.hasExclusive) {\n\t\t\t\t\tconst err = new AvaError('Couldn\\'t find any matching tests');\n\t\t\t\t\terr.file = undefined;\n\t\t\t\t\terr.results = [];\n\t\t\t\t\treturn Promise.reject(err);\n\t\t\t\t}\n\n\t\t\t\tconst method = this.options.serial ? 'mapSeries' : 'map';\n\t\t\t\tconst options = {\n\t\t\t\t\trunOnlyExclusive: runStatus.hasExclusive\n\t\t\t\t};\n\n\t\t\t\treturn Promise[method](files, (file, index) => {\n\t\t\t\t\treturn tests[index].run(options).catch(err => {\n\t\t\t\t\t\terr.file = file;\n\t\t\t\t\t\tthis._handleError(runStatus, err);\n\t\t\t\t\t\treturn getBlankResults();\n\t\t\t\t\t});\n\t\t\t\t});\n\t\t\t})\n\t\t\t.catch(err => {\n\t\t\t\tthis._handleError(runStatus, err);\n\t\t\t\treturn err.results;\n\t\t\t})\n\t\t\t.tap(results => {\n\t\t\t\t// If no tests ran, make sure to tear down the child processes\n\t\t\t\tif (results.length === 0) {\n\t\t\t\t\ttests.forEach(test => {\n\t\t\t\t\t\ttest.send('teardown');\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t})\n\t\t\t.then(results => {\n\t\t\t\t// Cancel debounced _onTimeout() from firing\n\t\t\t\tif (this.options.timeout) {\n\t\t\t\t\tthis._cancelTimeout(runStatus);\n\t\t\t\t}\n\n\t\t\t\trunStatus.processResults(results);\n\n\t\t\t\treturn runStatus;\n\t\t\t});\n\t}\n\t_runWithPool(files, runStatus, concurrency) {\n\t\tconst tests = [];\n\t\tlet execArgvList;\n\n\t\trunStatus.on('timeout', () => {\n\t\t\ttests.forEach(fork => {\n\t\t\t\tfork.exit();\n\t\t\t});\n\t\t});\n\n\t\treturn this._computeForkExecArgs(files)\n\t\t\t.then(argvList => {\n\t\t\t\texecArgvList = argvList;\n\t\t\t})\n\t\t\t.return(files)\n\t\t\t.map((file, index) => {\n\t\t\t\treturn new Promise(resolve => {\n\t\t\t\t\tconst forkArgs = execArgvList[index];\n\t\t\t\t\tconst test = this._runFile(file, runStatus, forkArgs);\n\t\t\t\t\ttests.push(test);\n\n\t\t\t\t\t// If we're looking for matches, run every single test process in exclusive-only mode\n\t\t\t\t\tconst options = {\n\t\t\t\t\t\trunOnlyExclusive: this.options.match.length > 0\n\t\t\t\t\t};\n\n\t\t\t\t\tresolve(test.run(options));\n\t\t\t\t}).catch(err => {\n\t\t\t\t\terr.file = file;\n\t\t\t\t\tthis._handleError(runStatus, err);\n\t\t\t\t\treturn getBlankResults();\n\t\t\t\t});\n\t\t\t}, {concurrency})\n\t\t\t.then(results => {\n\t\t\t\t// Filter out undefined results (usually result of caught exceptions)\n\t\t\t\tresults = results.filter(Boolean);\n\n\t\t\t\t// Cancel debounced _onTimeout() from firing\n\t\t\t\tif (this.options.timeout) {\n\t\t\t\t\tthis._cancelTimeout(runStatus);\n\t\t\t\t}\n\n\t\t\t\tif (this.options.match.length > 0 && !runStatus.hasExclusive) {\n\t\t\t\t\tresults = [];\n\n\t\t\t\t\tconst err = new AvaError('Couldn\\'t find any matching tests');\n\t\t\t\t\tthis._handleError(runStatus, err);\n\t\t\t\t}\n\n\t\t\t\trunStatus.processResults(results);\n\n\t\t\t\treturn runStatus;\n\t\t\t});\n\t}\n}\n\nmodule.exports = Api;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/babel-config.js":"'use strict';\nconst fs = require('fs');\nconst path = require('path');\nconst chalk = require('chalk');\nconst figures = require('figures');\nconst configManager = require('hullabaloo-config-manager');\nconst md5Hex = require('md5-hex');\nconst mkdirp = require('mkdirp');\nconst colors = require('./colors');\n\nfunction validate(conf) {\n\tif (conf === undefined || conf === null) {\n\t\tconf = 'default';\n\t}\n\n\t// Check for valid babel config shortcuts (can be either `default` or `inherit`)\n\tconst isValidShortcut = conf === 'default' || conf === 'inherit';\n\n\tif (!conf || (typeof conf === 'string' && !isValidShortcut)) {\n\t\tlet message = colors.error(figures.cross);\n\t\tmessage += ' Unexpected Babel configuration for AVA. ';\n\t\tmessage += 'See ' + chalk.underline('https://github.com/avajs/ava#es2015-support') + ' for allowed values.';\n\n\t\tthrow new Error(message);\n\t}\n\n\treturn conf;\n}\n\nconst SOURCE = '(AVA) Base Babel config';\nconst AVA_DIR = path.join(__dirname, '..');\n\nfunction verifyExistingOptions(verifierFile, baseConfig, cache) {\n\treturn new Promise((resolve, reject) => {\n\t\ttry {\n\t\t\tresolve(fs.readFileSync(verifierFile));\n\t\t} catch (err) {\n\t\t\tif (err && err.code === 'ENOENT') {\n\t\t\t\tresolve(null);\n\t\t\t} else {\n\t\t\t\treject(err);\n\t\t\t}\n\t\t}\n\t})\n\t\t.then(buffer => {\n\t\t\tif (!buffer) {\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\tconst verifier = configManager.restoreVerifier(buffer);\n\t\t\tconst fixedSourceHashes = new Map();\n\t\t\tfixedSourceHashes.set(baseConfig.source, baseConfig.hash);\n\t\t\tif (baseConfig.extends) {\n\t\t\t\tfixedSourceHashes.set(baseConfig.extends.source, baseConfig.extends.hash);\n\t\t\t}\n\t\t\treturn verifier.verifyCurrentEnv({sources: fixedSourceHashes}, cache)\n\t\t\t\t.then(result => {\n\t\t\t\t\tif (!result.cacheKeys) {\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (result.dependenciesChanged) {\n\t\t\t\t\t\tfs.writeFileSync(verifierFile, result.verifier.toBuffer());\n\t\t\t\t\t}\n\n\t\t\t\t\treturn result.cacheKeys;\n\t\t\t\t});\n\t\t});\n}\n\nfunction resolveOptions(baseConfig, cache, optionsFile, verifierFile) {\n\treturn configManager.fromConfig(baseConfig, {cache})\n\t\t.then(result => {\n\t\t\tfs.writeFileSync(optionsFile, result.generateModule());\n\n\t\t\treturn result.createVerifier()\n\t\t\t\t.then(verifier => {\n\t\t\t\t\tfs.writeFileSync(verifierFile, verifier.toBuffer());\n\t\t\t\t\treturn verifier.cacheKeysForCurrentEnv();\n\t\t\t\t});\n\t\t});\n}\n\nfunction build(projectDir, cacheDir, userOptions, powerAssert) {\n\t// Compute a seed based on the Node.js version and the project directory.\n\t// Dependency hashes may vary based on the Node.js version, e.g. with the\n\t// @ava/stage-4 Babel preset. Sources and dependencies paths are absolute in\n\t// the generated module and verifier state. Those paths wouldn't necessarily\n\t// be valid if the project directory changes.\n\tconst seed = md5Hex([process.versions.node, projectDir]);\n\n\t// Ensure cacheDir exists\n\tmkdirp.sync(cacheDir);\n\n\t// The file names predict where valid options may be cached, and thus should\n\t// include the seed.\n\tconst optionsFile = path.join(cacheDir, `${seed}.babel-options.js`);\n\tconst verifierFile = path.join(cacheDir, `${seed}.verifier.bin`);\n\n\tconst baseOptions = {\n\t\tbabelrc: false,\n\t\tpresets: [\n\t\t\t['@ava/transform-test-files', {powerAssert}]\n\t\t]\n\t};\n\tif (userOptions === 'default') {\n\t\tbaseOptions.presets.unshift('@ava/stage-4');\n\t}\n\n\tconst baseConfig = configManager.createConfig({\n\t\tdir: AVA_DIR, // Presets are resolved relative to this directory\n\t\thash: md5Hex(JSON.stringify(baseOptions)),\n\t\tjson5: false,\n\t\toptions: baseOptions,\n\t\tsource: SOURCE\n\t});\n\n\tif (userOptions !== 'default') {\n\t\tbaseConfig.extend(configManager.createConfig({\n\t\t\tdir: projectDir,\n\t\t\toptions: userOptions === 'inherit' ?\n\t\t\t\t{babelrc: true} :\n\t\t\t\tuserOptions,\n\t\t\tsource: path.join(projectDir, 'package.json') + '#ava.babel',\n\t\t\thash: md5Hex(JSON.stringify(userOptions))\n\t\t}));\n\t}\n\n\tconst cache = configManager.prepareCache();\n\treturn verifyExistingOptions(verifierFile, baseConfig, cache)\n\t\t.then(cacheKeys => {\n\t\t\tif (cacheKeys) {\n\t\t\t\treturn cacheKeys;\n\t\t\t}\n\n\t\t\treturn resolveOptions(baseConfig, cache, optionsFile, verifierFile);\n\t\t})\n\t\t.then(cacheKeys => ({\n\t\t\tgetOptions: require(optionsFile).getOptions, // eslint-disable-line import/no-dynamic-require\n\t\t\t// Include the seed in the cache keys used to store compilation results.\n\t\t\tcacheKeys: Object.assign({seed}, cacheKeys)\n\t\t}));\n}\n\nmodule.exports = {\n\tvalidate,\n\tbuild\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/colors.js":"'use strict';\nconst chalk = require('chalk');\n\nmodule.exports = {\n\ttitle: chalk.bold.white,\n\terror: chalk.red,\n\tskip: chalk.yellow,\n\ttodo: chalk.blue,\n\tpass: chalk.green,\n\tduration: chalk.gray.dim,\n\terrorSource: chalk.gray,\n\terrorStack: chalk.gray,\n\tstack: chalk.red,\n\tinformation: chalk.magenta\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/caching-precompiler.js":"'use strict';\nconst path = require('path');\nconst fs = require('fs');\nconst convertSourceMap = require('convert-source-map');\nconst cachingTransform = require('caching-transform');\nconst packageHash = require('package-hash');\nconst stripBomBuf = require('strip-bom-buf');\nconst autoBind = require('auto-bind');\nconst md5Hex = require('md5-hex');\n\nfunction getSourceMap(filePath, code) {\n\tlet sourceMap = convertSourceMap.fromSource(code);\n\n\tif (!sourceMap) {\n\t\tconst dirPath = path.dirname(filePath);\n\t\tsourceMap = convertSourceMap.fromMapFileSource(code, dirPath);\n\t}\n\n\tif (sourceMap) {\n\t\tsourceMap = sourceMap.toObject();\n\t}\n\n\treturn sourceMap;\n}\n\nclass CachingPrecompiler {\n\tconstructor(options) {\n\t\tautoBind(this);\n\n\t\tthis.getBabelOptions = options.getBabelOptions;\n\t\tthis.babelCacheKeys = options.babelCacheKeys;\n\t\tthis.cacheDirPath = options.path;\n\t\tthis.fileHashes = {};\n\t\tthis.transform = this._createTransform();\n\t}\n\tprecompileFile(filePath) {\n\t\tif (!this.fileHashes[filePath]) {\n\t\t\tconst source = stripBomBuf(fs.readFileSync(filePath));\n\t\t\tthis.transform(source, filePath);\n\t\t}\n\n\t\treturn this.fileHashes[filePath];\n\t}\n\t// Conditionally called by caching-transform when precompiling is required\n\t_init() {\n\t\tthis.babel = require('babel-core');\n\t\treturn this._transform;\n\t}\n\t_transform(code, filePath, hash) {\n\t\tcode = code.toString();\n\n\t\tlet result;\n\t\tconst originalBabelDisableCache = process.env.BABEL_DISABLE_CACHE;\n\t\ttry {\n\t\t\t// Disable Babel's cache. AVA has good cache management already.\n\t\t\tprocess.env.BABEL_DISABLE_CACHE = '1';\n\n\t\t\tresult = this.babel.transform(code, Object.assign(this.getBabelOptions(), {\n\t\t\t\tinputSourceMap: getSourceMap(filePath, code),\n\t\t\t\tfilename: filePath,\n\t\t\t\tsourceMaps: true,\n\t\t\t\tast: false\n\t\t\t}));\n\t\t} finally {\n\t\t\t// Restore the original value. It is passed to workers, where users may\n\t\t\t// not want Babel's cache to be disabled.\n\t\t\tprocess.env.BABEL_DISABLE_CACHE = originalBabelDisableCache;\n\t\t}\n\n\t\t// Save source map\n\t\tconst mapPath = path.join(this.cacheDirPath, `${hash}.js.map`);\n\t\tfs.writeFileSync(mapPath, JSON.stringify(result.map));\n\n\t\t// Append source map comment to transformed code\n\t\t// So that other libraries (like nyc) can find the source map\n\t\tconst dirPath = path.dirname(filePath);\n\t\tconst relativeMapPath = path.relative(dirPath, mapPath);\n\t\tconst comment = convertSourceMap.generateMapFileComment(relativeMapPath);\n\n\t\treturn `${result.code}\\n${comment}`;\n\t}\n\t_createTransform() {\n\t\tconst salt = packageHash.sync([\n\t\t\trequire.resolve('../package.json'),\n\t\t\trequire.resolve('babel-core/package.json')\n\t\t], this.babelCacheKeys);\n\n\t\treturn cachingTransform({\n\t\t\tfactory: this._init,\n\t\t\tcacheDir: this.cacheDirPath,\n\t\t\thash: this._generateHash,\n\t\t\tsalt,\n\t\t\text: '.js'\n\t\t});\n\t}\n\t_generateHash(code, filePath, salt) {\n\t\tconst hash = md5Hex([code, filePath, salt]);\n\t\tthis.fileHashes[filePath] = hash;\n\t\treturn hash;\n\t}\n}\n\nmodule.exports = CachingPrecompiler;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/run-status.js":"'use strict';\nconst EventEmitter = require('events');\nconst chalk = require('chalk');\nconst flatten = require('arr-flatten');\nconst figures = require('figures');\nconst autoBind = require('auto-bind');\nconst prefixTitle = require('./prefix-title');\n\nfunction sum(arr, key) {\n\tlet result = 0;\n\n\tarr.forEach(item => {\n\t\tresult += item[key];\n\t});\n\n\treturn result;\n}\n\nclass RunStatus extends EventEmitter {\n\tconstructor(opts) {\n\t\tsuper();\n\n\t\topts = opts || {};\n\t\tthis.prefixTitles = opts.prefixTitles !== false;\n\t\tthis.hasExclusive = Boolean(opts.runOnlyExclusive);\n\t\tthis.base = opts.base || '';\n\t\tthis.rejectionCount = 0;\n\t\tthis.exceptionCount = 0;\n\t\tthis.passCount = 0;\n\t\tthis.knownFailureCount = 0;\n\t\tthis.skipCount = 0;\n\t\tthis.todoCount = 0;\n\t\tthis.failCount = 0;\n\t\tthis.fileCount = 0;\n\t\tthis.testCount = 0;\n\t\tthis.remainingCount = 0;\n\t\tthis.previousFailCount = 0;\n\t\tthis.knownFailures = [];\n\t\tthis.errors = [];\n\t\tthis.stats = [];\n\t\tthis.tests = [];\n\t\tthis.failFastEnabled = opts.failFast || false;\n\n\t\tautoBind(this);\n\t}\n\tobserveFork(emitter) {\n\t\temitter\n\t\t\t.on('teardown', this.handleTeardown)\n\t\t\t.on('stats', this.handleStats)\n\t\t\t.on('test', this.handleTest)\n\t\t\t.on('unhandledRejections', this.handleRejections)\n\t\t\t.on('uncaughtException', this.handleExceptions)\n\t\t\t.on('stdout', this.handleOutput.bind(this, 'stdout'))\n\t\t\t.on('stderr', this.handleOutput.bind(this, 'stderr'));\n\t}\n\thandleRejections(data) {\n\t\tthis.rejectionCount += data.rejections.length;\n\n\t\tdata.rejections.forEach(err => {\n\t\t\terr.type = 'rejection';\n\t\t\terr.file = data.file;\n\t\t\tthis.emit('error', err, this);\n\t\t\tthis.errors.push(err);\n\t\t});\n\t}\n\thandleExceptions(data) {\n\t\tthis.exceptionCount++;\n\t\tconst err = data.exception;\n\t\terr.type = 'exception';\n\t\terr.file = data.file;\n\t\tthis.emit('error', err, this);\n\t\tthis.errors.push(err);\n\t}\n\thandleTeardown(data) {\n\t\tthis.emit('dependencies', data.file, data.dependencies, this);\n\t}\n\thandleStats(stats) {\n\t\tthis.emit('stats', stats, this);\n\n\t\tif (stats.hasExclusive) {\n\t\t\tthis.hasExclusive = true;\n\t\t}\n\n\t\tthis.testCount += stats.testCount;\n\t}\n\thandleTest(test) {\n\t\ttest.title = this.prefixTitle(test.file) + test.title;\n\n\t\tif (test.error) {\n\t\t\tthis.errors.push(test);\n\t\t}\n\n\t\tif (test.failing && !test.error) {\n\t\t\tthis.knownFailures.push(test);\n\t\t}\n\n\t\tthis.emit('test', test, this);\n\t}\n\tprefixTitle(file) {\n\t\tif (!this.prefixTitles) {\n\t\t\treturn '';\n\t\t}\n\n\t\tconst separator = ' ' + chalk.gray.dim(figures.pointerSmall) + ' ';\n\n\t\treturn prefixTitle(file, this.base, separator);\n\t}\n\thandleOutput(channel, data) {\n\t\tthis.emit(channel, data, this);\n\t}\n\tprocessResults(results) {\n\t\t// Assemble stats from all tests\n\t\tthis.stats = results.map(result => result.stats);\n\t\tthis.tests = results.map(result => result.tests);\n\t\tthis.tests = flatten(this.tests);\n\t\tthis.passCount = sum(this.stats, 'passCount');\n\t\tthis.knownFailureCount = sum(this.stats, 'knownFailureCount');\n\t\tthis.skipCount = sum(this.stats, 'skipCount');\n\t\tthis.todoCount = sum(this.stats, 'todoCount');\n\t\tthis.failCount = sum(this.stats, 'failCount');\n\t\tthis.remainingCount = this.testCount - this.passCount - this.failCount - this.skipCount - this.todoCount - this.knownFailureCount;\n\t}\n}\n\nmodule.exports = RunStatus;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/prefix-title.js":"'use strict';\nconst path = require('path');\n\nmodule.exports = (file, base, separator) => {\n\tlet prefix = file\n\t\t// Only replace this.base if it is found at the start of the path\n\t\t.replace(base, (match, offset) => offset === 0 ? '' : match)\n\t\t.replace(/\\.spec/, '')\n\t\t.replace(/\\.test/, '')\n\t\t.replace(/test-/g, '')\n\t\t.replace(/\\.js$/, '')\n\t\t.split(path.sep)\n\t\t.filter(p => p !== '__tests__')\n\t\t.join(separator);\n\n\tif (prefix.length > 0) {\n\t\tprefix += separator;\n\t}\n\n\treturn prefix;\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/ava-error.js":"'use strict';\n\nclass AvaError extends Error {\n\tconstructor(message) {\n\t\tsuper(message);\n\t\tthis.name = 'AvaError';\n\t}\n}\n\nmodule.exports = AvaError;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/ava-files.js":"'use strict';\nconst fs = require('fs');\nconst path = require('path');\nconst Promise = require('bluebird');\nconst slash = require('slash');\nconst globby = require('globby');\nconst flatten = require('lodash.flatten');\nconst autoBind = require('auto-bind');\nconst defaultIgnore = require('ignore-by-default').directories();\nconst multimatch = require('multimatch');\n\nfunction handlePaths(files, excludePatterns, globOptions) {\n\t// Convert Promise to Bluebird\n\tfiles = Promise.resolve(globby(files.concat(excludePatterns), globOptions));\n\n\tconst searchedParents = new Set();\n\tconst foundFiles = new Set();\n\n\tfunction alreadySearchingParent(dir) {\n\t\tif (searchedParents.has(dir)) {\n\t\t\treturn true;\n\t\t}\n\n\t\tconst parentDir = path.dirname(dir);\n\n\t\tif (parentDir === dir) {\n\t\t\t// We have reached the root path\n\t\t\treturn false;\n\t\t}\n\n\t\treturn alreadySearchingParent(parentDir);\n\t}\n\n\treturn files\n\t\t.map(file => {\n\t\t\tfile = path.resolve(globOptions.cwd, file);\n\n\t\t\tif (fs.statSync(file).isDirectory()) {\n\t\t\t\tif (alreadySearchingParent(file)) {\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\n\t\t\t\tsearchedParents.add(file);\n\n\t\t\t\tlet pattern = path.join(file, '**', '*.js');\n\n\t\t\t\tif (process.platform === 'win32') {\n\t\t\t\t\t// Always use `/` in patterns, harmonizing matching across platforms\n\t\t\t\t\tpattern = slash(pattern);\n\t\t\t\t}\n\n\t\t\t\treturn handlePaths([pattern], excludePatterns, globOptions);\n\t\t\t}\n\n\t\t\t// `globby` returns slashes even on Windows. Normalize here so the file\n\t\t\t// paths are consistently platform-accurate as tests are run.\n\t\t\treturn path.normalize(file);\n\t\t})\n\t\t.then(flatten)\n\t\t.filter(file => file && path.extname(file) === '.js')\n\t\t.filter(file => {\n\t\t\tif (path.basename(file)[0] === '_' && globOptions.includeUnderscoredFiles !== true) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\treturn true;\n\t\t})\n\t\t.map(file => path.resolve(file))\n\t\t.filter(file => {\n\t\t\tconst alreadyFound = foundFiles.has(file);\n\t\t\tfoundFiles.add(file);\n\t\t\treturn !alreadyFound;\n\t\t});\n}\n\nconst defaultExcludePatterns = () => [\n\t'!**/node_modules/**',\n\t'!**/fixtures/**',\n\t'!**/helpers/**'\n];\n\nconst defaultIncludePatterns = () => [\n\t'test.js',\n\t'test-*.js',\n\t'test',\n\t'**/__tests__',\n\t'**/*.test.js'\n];\n\nconst defaultHelperPatterns = () => [\n\t'**/__tests__/helpers/**/*.js',\n\t'**/__tests__/**/_*.js',\n\t'**/test/helpers/**/*.js',\n\t'**/test/**/_*.js'\n];\n\nconst getDefaultIgnorePatterns = () => defaultIgnore.map(dir => `${dir}/**/*`);\n\n// Used on paths before they're passed to multimatch to harmonize matching\n// across platforms\nconst matchable = process.platform === 'win32' ? slash : (path => path);\n\nclass AvaFiles {\n\tconstructor(options) {\n\t\toptions = options || {};\n\n\t\tlet files = (options.files || []).map(file => {\n\t\t\t// `./` should be removed from the beginning of patterns because\n\t\t\t// otherwise they won't match change events from Chokidar\n\t\t\tif (file.slice(0, 2) === './') {\n\t\t\t\treturn file.slice(2);\n\t\t\t}\n\n\t\t\treturn file;\n\t\t});\n\n\t\tif (files.length === 0) {\n\t\t\tfiles = defaultIncludePatterns();\n\t\t}\n\n\t\tthis.excludePatterns = defaultExcludePatterns();\n\t\tthis.files = files;\n\t\tthis.sources = options.sources || [];\n\t\tthis.cwd = options.cwd || process.cwd();\n\n\t\tautoBind(this);\n\t}\n\tfindTestFiles() {\n\t\treturn handlePaths(this.files, this.excludePatterns, {\n\t\t\tcwd: this.cwd,\n\t\t\tcache: Object.create(null),\n\t\t\tstatCache: Object.create(null),\n\t\t\trealpathCache: Object.create(null),\n\t\t\tsymlinks: Object.create(null)\n\t\t});\n\t}\n\tfindTestHelpers() {\n\t\treturn handlePaths(defaultHelperPatterns(), ['!**/node_modules/**'], {\n\t\t\tcwd: this.cwd,\n\t\t\tincludeUnderscoredFiles: true,\n\t\t\tcache: Object.create(null),\n\t\t\tstatCache: Object.create(null),\n\t\t\trealpathCache: Object.create(null),\n\t\t\tsymlinks: Object.create(null)\n\t\t});\n\t}\n\tisSource(filePath) {\n\t\tlet mixedPatterns = [];\n\t\tconst defaultIgnorePatterns = getDefaultIgnorePatterns();\n\t\tconst overrideDefaultIgnorePatterns = [];\n\n\t\tlet hasPositivePattern = false;\n\t\tthis.sources.forEach(pattern => {\n\t\t\tmixedPatterns.push(pattern);\n\n\t\t\t// TODO: Why not just `pattern[0] !== '!'`?\n\t\t\tif (!hasPositivePattern && pattern[0] !== '!') {\n\t\t\t\thasPositivePattern = true;\n\t\t\t}\n\n\t\t\t// Extract patterns that start with an ignored directory. These need to be\n\t\t\t// rematched separately.\n\t\t\tif (defaultIgnore.indexOf(pattern.split('/')[0]) >= 0) {\n\t\t\t\toverrideDefaultIgnorePatterns.push(pattern);\n\t\t\t}\n\t\t});\n\n\t\t// Same defaults as used for Chokidar\n\t\tif (!hasPositivePattern) {\n\t\t\tmixedPatterns = ['package.json', '**/*.js'].concat(mixedPatterns);\n\t\t}\n\n\t\tfilePath = matchable(filePath);\n\n\t\t// Ignore paths outside the current working directory.\n\t\t// They can't be matched to a pattern.\n\t\tif (/^\\.\\.\\//.test(filePath)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tconst isSource = multimatch(filePath, mixedPatterns).length === 1;\n\t\tif (!isSource) {\n\t\t\treturn false;\n\t\t}\n\n\t\tconst isIgnored = multimatch(filePath, defaultIgnorePatterns).length === 1;\n\t\tif (!isIgnored) {\n\t\t\treturn true;\n\t\t}\n\n\t\tconst isErroneouslyIgnored = multimatch(filePath, overrideDefaultIgnorePatterns).length === 1;\n\t\tif (isErroneouslyIgnored) {\n\t\t\treturn true;\n\t\t}\n\n\t\treturn false;\n\t}\n\tisTest(filePath) {\n\t\tconst excludePatterns = this.excludePatterns;\n\t\tconst initialPatterns = this.files.concat(excludePatterns);\n\n\t\t// Like in `api.js`, tests must be `.js` files and not start with `_`\n\t\tif (path.extname(filePath) !== '.js' || path.basename(filePath)[0] === '_') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// Check if the entire path matches a pattern\n\t\tif (multimatch(matchable(filePath), initialPatterns).length === 1) {\n\t\t\treturn true;\n\t\t}\n\n\t\t// Check if the path contains any directory components\n\t\tconst dirname = path.dirname(filePath);\n\t\tif (dirname === '.') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// Compute all possible subpaths. Note that the dirname is assumed to be\n\t\t// relative to the working directory, without a leading `./`.\n\t\tconst subpaths = dirname.split(/[\\\\/]/).reduce((subpaths, component) => {\n\t\t\tconst parent = subpaths[subpaths.length - 1];\n\n\t\t\tif (parent) {\n\t\t\t\t// Always use `/`` to makes multimatch consistent across platforms\n\t\t\t\tsubpaths.push(`${parent}/${component}`);\n\t\t\t} else {\n\t\t\t\tsubpaths.push(component);\n\t\t\t}\n\n\t\t\treturn subpaths;\n\t\t}, []);\n\n\t\t// Check if any of the possible subpaths match a pattern. If so, generate a\n\t\t// new pattern with **/*.js.\n\t\tconst recursivePatterns = subpaths\n\t\t\t.filter(subpath => multimatch(subpath, initialPatterns).length === 1)\n\t\t\t// Always use `/` to makes multimatch consistent across platforms\n\t\t\t.map(subpath => `${subpath}/**/*.js`);\n\n\t\t// See if the entire path matches any of the subpaths patterns, taking the\n\t\t// excludePatterns into account. This mimicks the behavior in api.js\n\t\treturn multimatch(matchable(filePath), recursivePatterns.concat(excludePatterns)).length === 1;\n\t}\n\tgetChokidarPatterns() {\n\t\tlet paths = [];\n\t\tlet ignored = [];\n\n\t\tthis.sources.forEach(pattern => {\n\t\t\tif (pattern[0] === '!') {\n\t\t\t\tignored.push(pattern.slice(1));\n\t\t\t} else {\n\t\t\t\tpaths.push(pattern);\n\t\t\t}\n\t\t});\n\n\t\t// Allow source patterns to override the default ignore patterns. Chokidar\n\t\t// ignores paths that match the list of ignored patterns. It uses anymatch\n\t\t// under the hood, which supports negation patterns. For any source pattern\n\t\t// that starts with an ignored directory, ensure the corresponding negation\n\t\t// pattern is added to the ignored paths.\n\t\tconst overrideDefaultIgnorePatterns = paths\n\t\t\t.filter(pattern => defaultIgnore.indexOf(pattern.split('/')[0]) >= 0)\n\t\t\t.map(pattern => `!${pattern}`);\n\n\t\tignored = getDefaultIgnorePatterns().concat(ignored, overrideDefaultIgnorePatterns);\n\n\t\tif (paths.length === 0) {\n\t\t\tpaths = ['package.json', '**/*.js'];\n\t\t}\n\n\t\tpaths = paths.concat(this.files);\n\n\t\treturn {\n\t\t\tpaths,\n\t\t\tignored\n\t\t};\n\t}\n}\n\nmodule.exports = AvaFiles;\nmodule.exports.defaultIncludePatterns = defaultIncludePatterns;\nmodule.exports.defaultExcludePatterns = defaultExcludePatterns;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/fork.js":"'use strict';\nconst childProcess = require('child_process');\nconst path = require('path');\nconst fs = require('fs');\nconst Promise = require('bluebird');\nconst debug = require('debug')('ava');\nconst AvaError = require('./ava-error');\n\nif (fs.realpathSync(__filename) !== __filename) {\n\tconsole.warn('WARNING: `npm link ava` and the `--preserve-symlink` flag are incompatible. We have detected that AVA is linked via `npm link`, and that you are using either an early version of Node 6, or the `--preserve-symlink` flag. This breaks AVA. You should upgrade to Node 6.2.0+, avoid the `--preserve-symlink` flag, or avoid using `npm link ava`.');\n}\n\nlet env = process.env;\n\n// Ensure NODE_PATH paths are absolute\nif (env.NODE_PATH) {\n\tenv = Object.assign({}, env);\n\n\tenv.NODE_PATH = env.NODE_PATH\n\t\t.split(path.delimiter)\n\t\t.map(x => path.resolve(x))\n\t\t.join(path.delimiter);\n}\n\n// In case the test file imports a different AVA install,\n// the presence of this variable allows it to require this one instead\nenv.AVA_PATH = path.resolve(__dirname, '..');\n\nmodule.exports = (file, opts, execArgv) => {\n\topts = Object.assign({\n\t\tfile,\n\t\tbaseDir: process.cwd(),\n\t\ttty: process.stdout.isTTY ? {\n\t\t\tcolumns: process.stdout.columns,\n\t\t\trows: process.stdout.rows\n\t\t} : false\n\t}, opts);\n\n\tconst args = [JSON.stringify(opts), opts.color ? '--color' : '--no-color'];\n\n\tconst ps = childProcess.fork(path.join(__dirname, 'test-worker.js'), args, {\n\t\tcwd: opts.projectDir,\n\t\tsilent: true,\n\t\tenv,\n\t\texecArgv: execArgv || process.execArgv\n\t});\n\n\tconst relFile = path.relative('.', file);\n\n\tlet exiting = false;\n\tconst send = (name, data) => {\n\t\tif (!exiting) {\n\t\t\t// This seems to trigger a Node bug which kills the AVA master process, at\n\t\t\t// least while running AVA's tests. See\n\t\t\t// <https://github.com/novemberborn/_ava-tap-crash> for more details.\n\t\t\tps.send({\n\t\t\t\tname: `ava-${name}`,\n\t\t\t\tdata,\n\t\t\t\tava: true\n\t\t\t});\n\t\t}\n\t};\n\n\tconst testResults = [];\n\tlet results;\n\n\tconst promise = new Promise((resolve, reject) => {\n\t\tps.on('error', reject);\n\n\t\t// Emit `test` and `stats` events\n\t\tps.on('message', event => {\n\t\t\tif (!event.ava) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tevent.name = event.name.replace(/^ava-/, '');\n\t\t\tevent.data.file = relFile;\n\n\t\t\tdebug('ipc %s:\\n%o', event.name, event.data);\n\n\t\t\tps.emit(event.name, event.data);\n\t\t});\n\n\t\tps.on('test', props => {\n\t\t\ttestResults.push(props);\n\t\t});\n\n\t\tps.on('results', data => {\n\t\t\tresults = data;\n\t\t\tdata.tests = testResults;\n\t\t\tsend('teardown');\n\t\t});\n\n\t\tps.on('exit', (code, signal) => {\n\t\t\tif (code > 0) {\n\t\t\t\treturn reject(new AvaError(`${relFile} exited with a non-zero exit code: ${code}`));\n\t\t\t}\n\n\t\t\tif (code === null && signal) {\n\t\t\t\treturn reject(new AvaError(`${relFile} exited due to ${signal}`));\n\t\t\t}\n\n\t\t\tif (results) {\n\t\t\t\tresolve(results);\n\t\t\t} else {\n\t\t\t\treject(new AvaError(`Test results were not received from ${relFile}`));\n\t\t\t}\n\t\t});\n\n\t\tps.on('no-tests', data => {\n\t\t\tsend('teardown');\n\n\t\t\tlet message = `No tests found in ${relFile}`;\n\n\t\t\tif (!data.avaRequired) {\n\t\t\t\tmessage += ', make sure to import \"ava\" at the top of your test file';\n\t\t\t}\n\n\t\t\treject(new AvaError(message));\n\t\t});\n\t});\n\n\t// Teardown finished, now exit\n\tps.on('teardown', () => {\n\t\tsend('exit');\n\t\texiting = true;\n\t});\n\n\t// Uncaught exception in fork, need to exit\n\tps.on('uncaughtException', () => {\n\t\tsend('teardown');\n\t});\n\n\tps.stdout.on('data', data => {\n\t\tps.emit('stdout', data);\n\t});\n\n\tps.stderr.on('data', data => {\n\t\tps.emit('stderr', data);\n\t});\n\n\tpromise.on = function () {\n\t\tps.on.apply(ps, arguments);\n\t\treturn promise;\n\t};\n\n\tpromise.send = (name, data) => {\n\t\tsend(name, data);\n\t\treturn promise;\n\t};\n\n\tpromise.exit = () => {\n\t\tsend('init-exit');\n\t\treturn promise;\n\t};\n\n\t// Send 'run' event only when fork is listening for it\n\tlet isReady = false;\n\n\tps.on('stats', () => {\n\t\tisReady = true;\n\t});\n\n\tpromise.run = options => {\n\t\tif (isReady) {\n\t\t\tsend('run', options);\n\t\t\treturn promise;\n\t\t}\n\n\t\tps.on('stats', () => {\n\t\t\tsend('run', options);\n\t\t});\n\n\t\treturn promise;\n\t};\n\n\treturn promise;\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/cli.js":"#!/usr/bin/env node\n'use strict';\nconst path = require('path');\nconst debug = require('debug')('ava');\n\n// Prefer the local installation of AVA.\nconst resolveCwd = require('resolve-cwd');\nconst localCLI = resolveCwd('ava/cli');\n\n// Use `path.relative()` to detect local AVA installation,\n// because __filename's case is inconsistent on Windows\n// see https://github.com/nodejs/node/issues/6624\nif (localCLI && path.relative(localCLI, __filename) !== '') {\n\tdebug('Using local install of AVA');\n\trequire(localCLI); // eslint-disable-line import/no-dynamic-require\n} else {\n\tif (debug.enabled) {\n\t\trequire('time-require'); // eslint-disable-line import/no-unassigned-import\n\t}\n\n\ttry {\n\t\trequire('./lib/cli').run();\n\t} catch (err) {\n\t\tconsole.error(`\\n  ${err.message}`);\n\t\tprocess.exit(1);\n\t}\n}\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/cli.js":"'use strict';\nconst path = require('path');\nconst updateNotifier = require('update-notifier');\nconst figures = require('figures');\nconst arrify = require('arrify');\nconst meow = require('meow');\nconst Promise = require('bluebird');\nconst pkgConf = require('pkg-conf');\nconst isCi = require('is-ci');\nconst hasFlag = require('has-flag');\nconst Api = require('../api');\nconst colors = require('./colors');\nconst VerboseReporter = require('./reporters/verbose');\nconst MiniReporter = require('./reporters/mini');\nconst TapReporter = require('./reporters/tap');\nconst Logger = require('./logger');\nconst Watcher = require('./watcher');\nconst babelConfigHelper = require('./babel-config');\n\n// Bluebird specific\nPromise.longStackTraces();\n\nexports.run = () => {\n\tconst conf = pkgConf.sync('ava');\n\n\tconst filepath = pkgConf.filepath(conf);\n\tconst projectDir = filepath === null ? process.cwd() : path.dirname(filepath);\n\n\tconst cli = meow(`\n\t\tUsage\n\t\t  ava [<file|directory|glob> ...]\n\n\t\tOptions\n\t\t  --init                  Add AVA to your project\n\t\t  --fail-fast             Stop after first test failure\n\t\t  --serial, -s            Run tests serially\n\t\t  --tap, -t               Generate TAP output\n\t\t  --verbose, -v           Enable verbose output\n\t\t  --no-cache              Disable the transpiler cache\n\t\t  --no-power-assert       Disable Power Assert\n\t\t  --color                 Force color output\n\t\t  --no-color              Disable color output\n\t\t  --match, -m             Only run tests with matching title (Can be repeated)\n\t\t  --watch, -w             Re-run tests when tests and source files change\n\t\t  --timeout, -T           Set global timeout\n\t\t  --concurrency, -c       Maximum number of test files running at the same time (EXPERIMENTAL)\n\t\t  --update-snapshots, -u  Update snapshots\n\n\t\tExamples\n\t\t  ava\n\t\t  ava test.js test2.js\n\t\t  ava test-*.js\n\t\t  ava test\n\t\t  ava --init\n\t\t  ava --init foo.js\n\n\t\tDefault patterns when no arguments:\n\t\ttest.js test-*.js test/**/*.js **/__tests__/**/*.js **/*.test.js\n\t`, {\n\t\tstring: [\n\t\t\t'_',\n\t\t\t'match',\n\t\t\t'timeout',\n\t\t\t'concurrency'\n\t\t],\n\t\tboolean: [\n\t\t\t'init',\n\t\t\t'fail-fast',\n\t\t\t'serial',\n\t\t\t'tap',\n\t\t\t'verbose',\n\t\t\t'watch',\n\t\t\t'update-snapshots',\n\t\t\t'color'\n\t\t],\n\t\tdefault: {\n\t\t\tcache: conf.cache,\n\t\t\tcolor: 'color' in conf ? conf.color : require('supports-color') !== false,\n\t\t\tconcurrency: conf.concurrency,\n\t\t\tfailFast: conf.failFast,\n\t\t\tinit: conf.init,\n\t\t\tmatch: conf.match,\n\t\t\tpowerAssert: conf.powerAssert,\n\t\t\tserial: conf.serial,\n\t\t\ttap: conf.tap,\n\t\t\ttimeout: conf.timeout,\n\t\t\tupdateSnapshots: conf.updateSnapshots,\n\t\t\tverbose: conf.verbose,\n\t\t\twatch: conf.watch\n\t\t},\n\t\talias: {\n\t\t\tt: 'tap',\n\t\t\tv: 'verbose',\n\t\t\ts: 'serial',\n\t\t\tm: 'match',\n\t\t\tw: 'watch',\n\t\t\tT: 'timeout',\n\t\t\tc: 'concurrency',\n\t\t\tu: 'update-snapshots'\n\t\t}\n\t});\n\n\tupdateNotifier({pkg: cli.pkg}).notify();\n\n\tif (cli.flags.init) {\n\t\trequire('ava-init')();\n\t\treturn;\n\t}\n\n\tif (\n\t\t((hasFlag('--watch') || hasFlag('-w')) && (hasFlag('--tap') || hasFlag('-t'))) ||\n\t\t(conf.watch && conf.tap)\n\t) {\n\t\tthrow new Error(colors.error(figures.cross) + ' The TAP reporter is not available when using watch mode.');\n\t}\n\n\tif ((hasFlag('--watch') || hasFlag('-w')) && isCi) {\n\t\tthrow new Error(colors.error(figures.cross) + ' Watch mode is not available in CI, as it prevents AVA from terminating.');\n\t}\n\n\tif (hasFlag('--require') || hasFlag('-r')) {\n\t\tthrow new Error(colors.error(figures.cross) + ' The --require and -r flags are deprecated. Requirements should be configured in package.json - see documentation.');\n\t}\n\n\t// Copy resultant cli.flags into conf for use with Api and elsewhere\n\tObject.assign(conf, cli.flags);\n\n\tconst api = new Api({\n\t\tfailFast: conf.failFast,\n\t\tfailWithoutAssertions: conf.failWithoutAssertions !== false,\n\t\tserial: conf.serial,\n\t\trequire: arrify(conf.require),\n\t\tcacheEnabled: conf.cache !== false,\n\t\tpowerAssert: conf.powerAssert !== false,\n\t\texplicitTitles: conf.watch,\n\t\tmatch: arrify(conf.match),\n\t\tbabelConfig: babelConfigHelper.validate(conf.babel),\n\t\tresolveTestsFrom: cli.input.length === 0 ? projectDir : process.cwd(),\n\t\tprojectDir,\n\t\ttimeout: conf.timeout,\n\t\tconcurrency: conf.concurrency ? parseInt(conf.concurrency, 10) : 0,\n\t\tupdateSnapshots: conf.updateSnapshots,\n\t\tcolor: conf.color\n\t});\n\n\tlet reporter;\n\n\tif (conf.tap && !conf.watch) {\n\t\treporter = new TapReporter();\n\t} else if (conf.verbose || isCi) {\n\t\treporter = new VerboseReporter({color: conf.color});\n\t} else {\n\t\treporter = new MiniReporter({color: conf.color, watching: conf.watch});\n\t}\n\n\treporter.api = api;\n\tconst logger = new Logger(reporter);\n\n\tlogger.start();\n\n\tapi.on('test-run', runStatus => {\n\t\treporter.api = runStatus;\n\t\trunStatus.on('test', logger.test);\n\t\trunStatus.on('error', logger.unhandledError);\n\n\t\trunStatus.on('stdout', logger.stdout);\n\t\trunStatus.on('stderr', logger.stderr);\n\t});\n\n\tconst files = cli.input.length ? cli.input : arrify(conf.files);\n\n\tif (conf.watch) {\n\t\ttry {\n\t\t\tconst watcher = new Watcher(logger, api, files, arrify(conf.source));\n\t\t\twatcher.observeStdin(process.stdin);\n\t\t} catch (err) {\n\t\t\tif (err.name === 'AvaError') {\n\t\t\t\t// An AvaError may be thrown if `chokidar` is not installed. Log it nicely.\n\t\t\t\tconsole.error(`  ${colors.error(figures.cross)} ${err.message}`);\n\t\t\t\tlogger.exit(1);\n\t\t\t} else {\n\t\t\t\t// Rethrow so it becomes an uncaught exception\n\t\t\t\tthrow err;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tapi.run(files)\n\t\t\t.then(runStatus => {\n\t\t\t\tlogger.finish(runStatus);\n\t\t\t\tlogger.exit(runStatus.failCount > 0 || runStatus.rejectionCount > 0 || runStatus.exceptionCount > 0 ? 1 : 0);\n\t\t\t})\n\t\t\t.catch(err => {\n\t\t\t\t// Don't swallow exceptions. Note that any expected error should already\n\t\t\t\t// have been logged.\n\t\t\t\tsetImmediate(() => {\n\t\t\t\t\tthrow err;\n\t\t\t\t});\n\t\t\t});\n\t}\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/reporters/verbose.js":"'use strict';\nconst indentString = require('indent-string');\nconst prettyMs = require('pretty-ms');\nconst figures = require('figures');\nconst chalk = require('chalk');\nconst plur = require('plur');\nconst formatAssertError = require('../format-assert-error');\nconst extractStack = require('../extract-stack');\nconst codeExcerpt = require('../code-excerpt');\nconst colors = require('../colors');\nconst improperUsageMessages = require('./improper-usage-messages');\n\nclass VerboseReporter {\n\tconstructor(options) {\n\t\tthis.options = Object.assign({}, options);\n\n\t\tchalk.enabled = this.options.color;\n\t\tfor (const key of Object.keys(colors)) {\n\t\t\tcolors[key].enabled = this.options.color;\n\t\t}\n\t}\n\tstart() {\n\t\treturn '';\n\t}\n\ttest(test, runStatus) {\n\t\tif (test.error) {\n\t\t\treturn '  ' + colors.error(figures.cross) + ' ' + test.title + ' ' + colors.error(test.error.message);\n\t\t}\n\n\t\tif (test.todo) {\n\t\t\treturn '  ' + colors.todo('- ' + test.title);\n\t\t} else if (test.skip) {\n\t\t\treturn '  ' + colors.skip('- ' + test.title);\n\t\t}\n\n\t\tif (test.failing) {\n\t\t\treturn '  ' + colors.error(figures.tick) + ' ' + colors.error(test.title);\n\t\t}\n\n\t\tif (runStatus.fileCount === 1 && runStatus.testCount === 1 && test.title === '[anonymous]') {\n\t\t\treturn undefined;\n\t\t}\n\n\t\t// Display duration only over a threshold\n\t\tconst threshold = 100;\n\t\tconst duration = test.duration > threshold ? colors.duration(' (' + prettyMs(test.duration) + ')') : '';\n\n\t\treturn '  ' + colors.pass(figures.tick) + ' ' + test.title + duration;\n\t}\n\tunhandledError(err) {\n\t\tif (err.type === 'exception' && err.name === 'AvaError') {\n\t\t\treturn colors.error('  ' + figures.cross + ' ' + err.message);\n\t\t}\n\n\t\tconst types = {\n\t\t\trejection: 'Unhandled Rejection',\n\t\t\texception: 'Uncaught Exception'\n\t\t};\n\n\t\tlet output = colors.error(types[err.type] + ':', err.file) + '\\n';\n\n\t\tif (err.stack) {\n\t\t\toutput += '  ' + colors.stack(err.stack) + '\\n';\n\t\t} else {\n\t\t\toutput += '  ' + colors.stack(JSON.stringify(err)) + '\\n';\n\t\t}\n\n\t\toutput += '\\n';\n\n\t\treturn output;\n\t}\n\tfinish(runStatus) {\n\t\tlet output = '\\n';\n\n\t\tconst lines = [\n\t\t\trunStatus.failCount > 0 ?\n\t\t\t\t'  ' + colors.error(runStatus.failCount, plur('test', runStatus.failCount), 'failed') :\n\t\t\t\t'  ' + colors.pass(runStatus.passCount, plur('test', runStatus.passCount), 'passed'),\n\t\t\trunStatus.knownFailureCount > 0 ? '  ' + colors.error(runStatus.knownFailureCount, plur('known failure', runStatus.knownFailureCount)) : '',\n\t\t\trunStatus.skipCount > 0 ? '  ' + colors.skip(runStatus.skipCount, plur('test', runStatus.skipCount), 'skipped') : '',\n\t\t\trunStatus.todoCount > 0 ? '  ' + colors.todo(runStatus.todoCount, plur('test', runStatus.todoCount), 'todo') : '',\n\t\t\trunStatus.rejectionCount > 0 ? '  ' + colors.error(runStatus.rejectionCount, 'unhandled', plur('rejection', runStatus.rejectionCount)) : '',\n\t\t\trunStatus.exceptionCount > 0 ? '  ' + colors.error(runStatus.exceptionCount, 'uncaught', plur('exception', runStatus.exceptionCount)) : '',\n\t\t\trunStatus.previousFailCount > 0 ? '  ' + colors.error(runStatus.previousFailCount, 'previous', plur('failure', runStatus.previousFailCount), 'in test files that were not rerun') : ''\n\t\t].filter(Boolean);\n\n\t\tif (lines.length > 0) {\n\t\t\tlines[0] += ' ' + chalk.gray.dim('[' + new Date().toLocaleTimeString('en-US', {hour12: false}) + ']');\n\t\t\toutput += lines.join('\\n');\n\t\t}\n\n\t\tif (runStatus.knownFailureCount > 0) {\n\t\t\trunStatus.knownFailures.forEach(test => {\n\t\t\t\toutput += '\\n\\n\\n  ' + colors.error(test.title);\n\t\t\t});\n\t\t}\n\n\t\tif (runStatus.failCount > 0) {\n\t\t\trunStatus.tests.forEach((test, index) => {\n\t\t\t\tif (!test.error) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tconst beforeSpacing = index === 0 ? '\\n\\n' : '\\n\\n\\n\\n';\n\t\t\t\toutput += beforeSpacing + '  ' + colors.title(test.title) + '\\n';\n\t\t\t\tif (test.error.source) {\n\t\t\t\t\toutput += '  ' + colors.errorSource(test.error.source.file + ':' + test.error.source.line) + '\\n';\n\n\t\t\t\t\tconst excerpt = codeExcerpt(test.error.source, {maxWidth: process.stdout.columns});\n\t\t\t\t\tif (excerpt) {\n\t\t\t\t\t\toutput += '\\n' + indentString(excerpt, 2) + '\\n';\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (test.error.message) {\n\t\t\t\t\toutput += '\\n' + indentString(test.error.message, 2) + '\\n';\n\t\t\t\t}\n\n\t\t\t\tif (test.error.avaAssertionError) {\n\t\t\t\t\tconst formatted = formatAssertError.formatSerializedError(test.error);\n\t\t\t\t\tif (formatted) {\n\t\t\t\t\t\toutput += '\\n' + indentString(formatted, 2);\n\t\t\t\t\t}\n\n\t\t\t\t\tconst message = improperUsageMessages.forError(test.error);\n\t\t\t\t\tif (message) {\n\t\t\t\t\t\toutput += '\\n' + indentString(message, 2) + '\\n';\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (test.error.stack) {\n\t\t\t\t\tconst extracted = extractStack(test.error.stack);\n\t\t\t\t\tif (extracted.includes('\\n')) {\n\t\t\t\t\t\toutput += '\\n' + indentString(colors.errorStack(extracted), 2);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\n\t\tif (runStatus.failFastEnabled === true && runStatus.remainingCount > 0 && runStatus.failCount > 0) {\n\t\t\tconst remaining = 'At least ' + runStatus.remainingCount + ' ' + plur('test was', 'tests were', runStatus.remainingCount) + ' skipped.';\n\t\t\toutput += '\\n\\n\\n  ' + colors.information('`--fail-fast` is on. ' + remaining);\n\t\t}\n\n\t\tif (runStatus.hasExclusive === true && runStatus.remainingCount > 0) {\n\t\t\toutput += '\\n\\n\\n  ' + colors.information('The .only() modifier is used in some tests.', runStatus.remainingCount, plur('test', runStatus.remainingCount), plur('was', 'were', runStatus.remainingCount), 'not run');\n\t\t}\n\n\t\treturn output + '\\n';\n\t}\n\tsection() {\n\t\treturn chalk.gray.dim('\\u2500'.repeat(process.stdout.columns || 80));\n\t}\n\twrite(str) {\n\t\tconsole.error(str);\n\t}\n\tstdout(data) {\n\t\tprocess.stderr.write(data);\n\t}\n\tstderr(data) {\n\t\tprocess.stderr.write(data);\n\t}\n}\n\nmodule.exports = VerboseReporter;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/format-assert-error.js":"'use strict';\nconst prettyFormat = require('@ava/pretty-format');\nconst reactTestPlugin = require('@ava/pretty-format/plugins/ReactTestComponent');\nconst chalk = require('chalk');\nconst diff = require('diff');\nconst DiffMatchPatch = require('diff-match-patch');\nconst indentString = require('indent-string');\nconst globals = require('./globals');\n\nfunction formatValue(value, options) {\n\treturn prettyFormat(value, Object.assign({\n\t\tcallToJSON: false,\n\t\tplugins: [reactTestPlugin],\n\t\thighlight: globals.options.color !== false\n\t}, options));\n}\nexports.formatValue = formatValue;\n\nconst cleanUp = line => {\n\tif (line[0] === '+') {\n\t\treturn `${chalk.green('+')} ${line.slice(1)}`;\n\t}\n\n\tif (line[0] === '-') {\n\t\treturn `${chalk.red('-')} ${line.slice(1)}`;\n\t}\n\n\tif (line.match(/@@/)) {\n\t\treturn null;\n\t}\n\n\tif (line.match(/\\\\ No newline/)) {\n\t\treturn null;\n\t}\n\n\treturn ` ${line}`;\n};\n\nconst getType = value => {\n\tconst type = typeof value;\n\tif (type === 'object') {\n\t\tif (type === null) {\n\t\t\treturn 'null';\n\t\t}\n\t\tif (Array.isArray(value)) {\n\t\t\treturn 'array';\n\t\t}\n\t}\n\treturn type;\n};\n\nfunction formatDiff(actual, expected) {\n\tconst actualType = getType(actual);\n\tconst expectedType = getType(expected);\n\tif (actualType !== expectedType) {\n\t\treturn null;\n\t}\n\n\tif (actualType === 'array' || actualType === 'object') {\n\t\tconst formatted = diff.createPatch('string', formatValue(actual), formatValue(expected))\n\t\t\t.split('\\n')\n\t\t\t.slice(4)\n\t\t\t.map(cleanUp)\n\t\t\t.filter(Boolean)\n\t\t\t.join('\\n')\n\t\t\t.trimRight();\n\n\t\treturn {label: 'Difference:', formatted};\n\t}\n\n\tif (actualType === 'string') {\n\t\tconst formatted = new DiffMatchPatch()\n\t\t\t.diff_main(formatValue(actual, {highlight: false}), formatValue(expected, {highlight: false}))\n\t\t\t.map(part => {\n\t\t\t\tif (part[0] === 1) {\n\t\t\t\t\treturn chalk.bgGreen.black(part[1]);\n\t\t\t\t}\n\n\t\t\t\tif (part[0] === -1) {\n\t\t\t\t\treturn chalk.bgRed.black(part[1]);\n\t\t\t\t}\n\n\t\t\t\treturn chalk.red(part[1]);\n\t\t\t})\n\t\t\t.join('')\n\t\t\t.trimRight();\n\n\t\treturn {label: 'Difference:', formatted};\n\t}\n\n\treturn null;\n}\nexports.formatDiff = formatDiff;\n\nfunction formatWithLabel(label, value) {\n\treturn {label, formatted: formatValue(value)};\n}\nexports.formatWithLabel = formatWithLabel;\n\nfunction formatSerializedError(error) {\n\tif (error.statements.length === 0 && error.values.length === 0) {\n\t\treturn null;\n\t}\n\n\tlet result = error.values\n\t\t.map(value => `${value.label}\\n\\n${indentString(value.formatted, 2).trimRight()}\\n`)\n\t\t.join('\\n');\n\n\tif (error.statements.length > 0) {\n\t\tif (error.values.length > 0) {\n\t\t\tresult += '\\n';\n\t\t}\n\n\t\tresult += error.statements\n\t\t\t.map(statement => `${statement[0]}\\n${chalk.grey('=>')} ${statement[1]}\\n`)\n\t\t\t.join('\\n');\n\t}\n\n\treturn result;\n}\nexports.formatSerializedError = formatSerializedError;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/globals.js":"'use strict';\n\n// Global objects / functions to be bound before requiring test file, so tests do not interfere\n\nconst x = module.exports;\nx.now = Date.now;\nx.setTimeout = setTimeout;\nx.clearTimeout = clearTimeout;\nx.setImmediate = setImmediate;\nx.options = {};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/extract-stack.js":"'use strict';\nconst stackLineRegex = /^.+ \\(.+:[0-9]+:[0-9]+\\)$/;\n\nmodule.exports = stack => {\n\treturn stack\n\t\t.split('\\n')\n\t\t.filter(line => stackLineRegex.test(line))\n\t\t.map(line => line.trim())\n\t\t.join('\\n');\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/code-excerpt.js":"'use strict';\nconst fs = require('fs');\nconst equalLength = require('equal-length');\nconst codeExcerpt = require('code-excerpt');\nconst truncate = require('cli-truncate');\nconst chalk = require('chalk');\n\nconst formatLineNumber = (lineNumber, maxLineNumber) =>\n\t' '.repeat(Math.max(0, String(maxLineNumber).length - String(lineNumber).length)) + lineNumber;\n\nmodule.exports = (source, options) => {\n\tif (!source.isWithinProject || source.isDependency) {\n\t\treturn null;\n\t}\n\n\tconst file = source.file;\n\tconst line = source.line;\n\n\toptions = options || {};\n\tconst maxWidth = options.maxWidth || 80;\n\n\tlet contents;\n\ttry {\n\t\tcontents = fs.readFileSync(file, 'utf8');\n\t} catch (err) {\n\t\treturn null;\n\t}\n\n\tconst excerpt = codeExcerpt(contents, line, {around: 1});\n\tif (!excerpt) {\n\t\treturn null;\n\t}\n\n\tconst lines = excerpt.map(item => ({\n\t\tline: item.line,\n\t\tvalue: truncate(item.value, maxWidth - String(line).length - 5)\n\t}));\n\n\tconst joinedLines = lines.map(line => line.value).join('\\n');\n\tconst extendedLines = equalLength(joinedLines).split('\\n');\n\n\treturn lines\n\t\t.map((item, index) => ({\n\t\t\tline: item.line,\n\t\t\tvalue: extendedLines[index]\n\t\t}))\n\t\t.map(item => {\n\t\t\tconst isErrorSource = item.line === line;\n\n\t\t\tconst lineNumber = formatLineNumber(item.line, line) + ':';\n\t\t\tconst coloredLineNumber = isErrorSource ? lineNumber : chalk.grey(lineNumber);\n\t\t\tconst result = ` ${coloredLineNumber} ${item.value}`;\n\n\t\t\treturn isErrorSource ? chalk.bgRed(result) : result;\n\t\t})\n\t\t.join('\\n');\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/reporters/improper-usage-messages.js":"'use strict';\nconst chalk = require('chalk');\n\nexports.forError = error => {\n\tif (!error.improperUsage) {\n\t\treturn null;\n\t}\n\n\tconst assertion = error.assertion;\n\tif (assertion !== 'throws' || !assertion === 'notThrows') {\n\t\treturn null;\n\t}\n\n\treturn `Try wrapping the first argument to \\`t.${assertion}()\\` in a function:\n\n  ${chalk.cyan(`t.${assertion}(() => { `)}${chalk.grey('/* your code here */')}${chalk.cyan(' })')}\n\nVisit the following URL for more details:\n\n  ${chalk.blue.underline('https://github.com/avajs/ava#throwsfunctionpromise-error-message')}`;\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/reporters/mini.js":"'use strict';\nconst StringDecoder = require('string_decoder').StringDecoder;\nconst cliCursor = require('cli-cursor');\nconst lastLineTracker = require('last-line-stream/tracker');\nconst plur = require('plur');\nconst spinners = require('cli-spinners');\nconst chalk = require('chalk');\nconst cliTruncate = require('cli-truncate');\nconst cross = require('figures').cross;\nconst indentString = require('indent-string');\nconst formatAssertError = require('../format-assert-error');\nconst extractStack = require('../extract-stack');\nconst codeExcerpt = require('../code-excerpt');\nconst colors = require('../colors');\nconst improperUsageMessages = require('./improper-usage-messages');\n\n// TODO(@jamestalamge): This should be fixed in log-update and ansi-escapes once we are confident it's a good solution.\nconst CSI = '\\u001B[';\nconst ERASE_LINE = CSI + '2K';\nconst CURSOR_TO_COLUMN_0 = CSI + '0G';\nconst CURSOR_UP = CSI + '1A';\n\n// Returns a string that will erase `count` lines from the end of the terminal.\nfunction eraseLines(count) {\n\tlet clear = '';\n\n\tfor (let i = 0; i < count; i++) {\n\t\tclear += ERASE_LINE + (i < count - 1 ? CURSOR_UP : '');\n\t}\n\n\tif (count) {\n\t\tclear += CURSOR_TO_COLUMN_0;\n\t}\n\n\treturn clear;\n}\n\nclass MiniReporter {\n\tconstructor(options) {\n\t\tthis.options = Object.assign({}, options);\n\n\t\tchalk.enabled = this.options.color;\n\t\tfor (const key of Object.keys(colors)) {\n\t\t\tcolors[key].enabled = this.options.color;\n\t\t}\n\n\t\tconst spinnerDef = spinners[process.platform === 'win32' ? 'line' : 'dots'];\n\t\tthis.spinnerFrames = spinnerDef.frames.map(c => chalk.gray.dim(c));\n\t\tthis.spinnerInterval = spinnerDef.interval;\n\n\t\tthis.reset();\n\t\tthis.stream = process.stderr;\n\t\tthis.stringDecoder = new StringDecoder();\n\t}\n\tstart() {\n\t\tthis.interval = setInterval(() => {\n\t\t\tthis.spinnerIndex = (this.spinnerIndex + 1) % this.spinnerFrames.length;\n\t\t\tthis.write(this.prefix());\n\t\t}, this.spinnerInterval);\n\n\t\treturn this.prefix('');\n\t}\n\treset() {\n\t\tthis.clearInterval();\n\t\tthis.passCount = 0;\n\t\tthis.knownFailureCount = 0;\n\t\tthis.failCount = 0;\n\t\tthis.skipCount = 0;\n\t\tthis.todoCount = 0;\n\t\tthis.rejectionCount = 0;\n\t\tthis.exceptionCount = 0;\n\t\tthis.currentStatus = '';\n\t\tthis.currentTest = '';\n\t\tthis.statusLineCount = 0;\n\t\tthis.spinnerIndex = 0;\n\t\tthis.lastLineTracker = lastLineTracker();\n\t}\n\tspinnerChar() {\n\t\treturn this.spinnerFrames[this.spinnerIndex];\n\t}\n\tclearInterval() {\n\t\tclearInterval(this.interval);\n\t\tthis.interval = null;\n\t}\n\ttest(test) {\n\t\tif (test.todo) {\n\t\t\tthis.todoCount++;\n\t\t} else if (test.skip) {\n\t\t\tthis.skipCount++;\n\t\t} else if (test.error) {\n\t\t\tthis.failCount++;\n\t\t} else {\n\t\t\tthis.passCount++;\n\t\t\tif (test.failing) {\n\t\t\t\tthis.knownFailureCount++;\n\t\t\t}\n\t\t}\n\n\t\tif (test.todo || test.skip) {\n\t\t\treturn;\n\t\t}\n\n\t\treturn this.prefix(this._test(test));\n\t}\n\tprefix(str) {\n\t\tstr = str || this.currentTest;\n\t\tthis.currentTest = str;\n\n\t\t// The space before the newline is required for proper formatting\n\t\t// TODO(jamestalmage): Figure out why it's needed and document it here\n\t\treturn ` \\n ${this.spinnerChar()} ${str}`;\n\t}\n\t_test(test) {\n\t\tconst SPINNER_WIDTH = 3;\n\t\tconst PADDING = 1;\n\t\tlet title = cliTruncate(test.title, process.stdout.columns - SPINNER_WIDTH - PADDING);\n\n\t\tif (test.error || test.failing) {\n\t\t\ttitle = colors.error(test.title);\n\t\t}\n\n\t\treturn title + '\\n' + this.reportCounts();\n\t}\n\tunhandledError(err) {\n\t\tif (err.type === 'exception') {\n\t\t\tthis.exceptionCount++;\n\t\t} else {\n\t\t\tthis.rejectionCount++;\n\t\t}\n\t}\n\treportCounts(time) {\n\t\tconst lines = [\n\t\t\tthis.passCount > 0 ? '\\n  ' + colors.pass(this.passCount, 'passed') : '',\n\t\t\tthis.knownFailureCount > 0 ? '\\n  ' + colors.error(this.knownFailureCount, plur('known failure', this.knownFailureCount)) : '',\n\t\t\tthis.failCount > 0 ? '\\n  ' + colors.error(this.failCount, 'failed') : '',\n\t\t\tthis.skipCount > 0 ? '\\n  ' + colors.skip(this.skipCount, 'skipped') : '',\n\t\t\tthis.todoCount > 0 ? '\\n  ' + colors.todo(this.todoCount, 'todo') : ''\n\t\t].filter(Boolean);\n\n\t\tif (time && lines.length > 0) {\n\t\t\tlines[0] += ' ' + time;\n\t\t}\n\n\t\treturn lines.join('');\n\t}\n\tfinish(runStatus) {\n\t\tthis.clearInterval();\n\t\tlet time;\n\n\t\tif (this.options.watching) {\n\t\t\ttime = chalk.gray.dim('[' + new Date().toLocaleTimeString('en-US', {hour12: false}) + ']');\n\t\t}\n\n\t\tlet status = this.reportCounts(time);\n\n\t\tif (this.rejectionCount > 0) {\n\t\t\tstatus += '\\n  ' + colors.error(this.rejectionCount, plur('rejection', this.rejectionCount));\n\t\t}\n\n\t\tif (this.exceptionCount > 0) {\n\t\t\tstatus += '\\n  ' + colors.error(this.exceptionCount, plur('exception', this.exceptionCount));\n\t\t}\n\n\t\tif (runStatus.previousFailCount > 0) {\n\t\t\tstatus += '\\n  ' + colors.error(runStatus.previousFailCount, 'previous', plur('failure', runStatus.previousFailCount), 'in test files that were not rerun');\n\t\t}\n\n\t\tif (this.knownFailureCount > 0) {\n\t\t\tfor (const test of runStatus.knownFailures) {\n\t\t\t\tconst title = test.title;\n\t\t\t\tstatus += '\\n\\n   ' + colors.title(title);\n\t\t\t\t// TODO: Output description with link\n\t\t\t\t// status += colors.stack(description);\n\t\t\t}\n\t\t}\n\n\t\tif (this.failCount > 0) {\n\t\t\trunStatus.errors.forEach((test, index) => {\n\t\t\t\tif (!test.error) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tconst beforeSpacing = index === 0 ? '\\n\\n' : '\\n\\n\\n\\n';\n\n\t\t\t\tstatus += beforeSpacing + '  ' + colors.title(test.title) + '\\n';\n\t\t\t\tif (test.error.source) {\n\t\t\t\t\tstatus += '  ' + colors.errorSource(test.error.source.file + ':' + test.error.source.line) + '\\n';\n\n\t\t\t\t\tconst excerpt = codeExcerpt(test.error.source, {maxWidth: process.stdout.columns});\n\t\t\t\t\tif (excerpt) {\n\t\t\t\t\t\tstatus += '\\n' + indentString(excerpt, 2) + '\\n';\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (test.error.message) {\n\t\t\t\t\tstatus += '\\n' + indentString(test.error.message, 2) + '\\n';\n\t\t\t\t}\n\n\t\t\t\tif (test.error.avaAssertionError) {\n\t\t\t\t\tconst formatted = formatAssertError.formatSerializedError(test.error);\n\t\t\t\t\tif (formatted) {\n\t\t\t\t\t\tstatus += '\\n' + indentString(formatted, 2);\n\t\t\t\t\t}\n\n\t\t\t\t\tconst message = improperUsageMessages.forError(test.error);\n\t\t\t\t\tif (message) {\n\t\t\t\t\t\tstatus += '\\n' + indentString(message, 2) + '\\n';\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (test.error.stack) {\n\t\t\t\t\tconst extracted = extractStack(test.error.stack);\n\t\t\t\t\tif (extracted.includes('\\n')) {\n\t\t\t\t\t\tstatus += '\\n' + indentString(colors.errorStack(extracted), 2);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\n\t\tif (this.rejectionCount > 0 || this.exceptionCount > 0) {\n\t\t\t// TODO(sindresorhus): Figure out why this causes a test failure when switched to a for-of loop\n\t\t\trunStatus.errors.forEach(err => {\n\t\t\t\tif (err.title) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (err.type === 'exception' && err.name === 'AvaError') {\n\t\t\t\t\tstatus += '\\n\\n  ' + colors.error(cross + ' ' + err.message);\n\t\t\t\t} else {\n\t\t\t\t\tconst title = err.type === 'rejection' ? 'Unhandled Rejection' : 'Uncaught Exception';\n\t\t\t\t\tlet description = err.stack ? err.stack.trimRight() : JSON.stringify(err);\n\t\t\t\t\tdescription = description.split('\\n');\n\t\t\t\t\tconst errorTitle = err.name ? description[0] : 'Threw non-error: ' + description[0];\n\t\t\t\t\tconst errorStack = description.slice(1).join('\\n');\n\n\t\t\t\t\tstatus += '\\n\\n  ' + colors.title(title) + '\\n';\n\t\t\t\t\tstatus += '  ' + colors.stack(errorTitle) + '\\n';\n\t\t\t\t\tstatus += colors.errorStack(errorStack);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\n\t\tif (runStatus.failFastEnabled === true && runStatus.remainingCount > 0 && runStatus.failCount > 0) {\n\t\t\tconst remaining = 'At least ' + runStatus.remainingCount + ' ' + plur('test was', 'tests were', runStatus.remainingCount) + ' skipped.';\n\t\t\tstatus += '\\n\\n  ' + colors.information('`--fail-fast` is on. ' + remaining);\n\t\t}\n\n\t\tif (runStatus.hasExclusive === true && runStatus.remainingCount > 0) {\n\t\t\tstatus += '\\n\\n  ' + colors.information('The .only() modifier is used in some tests.', runStatus.remainingCount, plur('test', runStatus.remainingCount), plur('was', 'were', runStatus.remainingCount), 'not run');\n\t\t}\n\n\t\treturn status + '\\n\\n';\n\t}\n\tsection() {\n\t\treturn '\\n' + chalk.gray.dim('\\u2500'.repeat(process.stdout.columns || 80));\n\t}\n\tclear() {\n\t\treturn '';\n\t}\n\twrite(str) {\n\t\tcliCursor.hide();\n\t\tthis.currentStatus = str;\n\t\tthis._update();\n\t\tthis.statusLineCount = this.currentStatus.split('\\n').length;\n\t}\n\tstdout(data) {\n\t\tthis._update(data);\n\t}\n\tstderr(data) {\n\t\tthis._update(data);\n\t}\n\t_update(data) {\n\t\tlet str = '';\n\t\tlet ct = this.statusLineCount;\n\t\tconst columns = process.stdout.columns;\n\t\tlet lastLine = this.lastLineTracker.lastLine();\n\n\t\t// Terminals automatically wrap text. We only need the last log line as seen on the screen.\n\t\tlastLine = lastLine.substring(lastLine.length - (lastLine.length % columns));\n\n\t\t// Don't delete the last log line if it's completely empty.\n\t\tif (lastLine.length > 0) {\n\t\t\tct++;\n\t\t}\n\n\t\t// Erase the existing status message, plus the last log line.\n\t\tstr += eraseLines(ct);\n\n\t\t// Rewrite the last log line.\n\t\tstr += lastLine;\n\n\t\tif (str.length > 0) {\n\t\t\tthis.stream.write(str);\n\t\t}\n\n\t\tif (data) {\n\t\t\t// Send new log data to the terminal, and update the last line status.\n\t\t\tthis.lastLineTracker.update(this.stringDecoder.write(data));\n\t\t\tthis.stream.write(data);\n\t\t}\n\n\t\tlet currentStatus = this.currentStatus;\n\n\t\tif (currentStatus.length > 0) {\n\t\t\tlastLine = this.lastLineTracker.lastLine();\n\t\t\t// We need a newline at the end of the last log line, before the status message.\n\t\t\t// However, if the last log line is the exact width of the terminal a newline is implied,\n\t\t\t// and adding a second will cause problems.\n\t\t\tif (lastLine.length % columns) {\n\t\t\t\tcurrentStatus = '\\n' + currentStatus;\n\t\t\t}\n\t\t\t// Rewrite the status message.\n\t\t\tthis.stream.write(currentStatus);\n\t\t}\n\t}\n}\n\nmodule.exports = MiniReporter;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/reporters/tap.js":"'use strict';\nconst format = require('util').format;\nconst indentString = require('indent-string');\nconst stripAnsi = require('strip-ansi');\nconst yaml = require('js-yaml');\nconst extractStack = require('../extract-stack');\n\n// Parses stack trace and extracts original function name, file name and line\nfunction getSourceFromStack(stack) {\n\treturn extractStack(stack).split('\\n')[0];\n}\n\nfunction dumpError(error, includeMessage) {\n\tconst obj = Object.assign({}, error.object);\n\tif (error.name) {\n\t\tobj.name = error.name;\n\t}\n\tif (includeMessage && error.message) {\n\t\tobj.message = error.message;\n\t}\n\n\tif (error.avaAssertionError) {\n\t\tif (error.assertion) {\n\t\t\tobj.assertion = error.assertion;\n\t\t}\n\t\tif (error.operator) {\n\t\t\tobj.operator = error.operator;\n\t\t}\n\t\tif (error.values.length > 0) {\n\t\t\tobj.values = error.values.reduce((acc, value) => {\n\t\t\t\tacc[value.label] = stripAnsi(value.formatted);\n\t\t\t\treturn acc;\n\t\t\t}, {});\n\t\t}\n\t}\n\n\tif (error.stack) {\n\t\tobj.at = getSourceFromStack(error.stack);\n\t}\n\n\treturn `  ---\\n${indentString(yaml.safeDump(obj).trim(), 4)}\\n  ...`;\n}\n\nclass TapReporter {\n\tconstructor() {\n\t\tthis.i = 0;\n\t}\n\tstart() {\n\t\treturn 'TAP version 13';\n\t}\n\ttest(test) {\n\t\tlet output;\n\n\t\tlet directive = '';\n\t\tconst passed = test.todo ? 'not ok' : 'ok';\n\n\t\tif (test.todo) {\n\t\t\tdirective = '# TODO';\n\t\t} else if (test.skip) {\n\t\t\tdirective = '# SKIP';\n\t\t}\n\n\t\tconst title = stripAnsi(test.title);\n\n\t\tif (test.error) {\n\t\t\toutput = [\n\t\t\t\t'# ' + title,\n\t\t\t\tformat('not ok %d - %s', ++this.i, title),\n\t\t\t\tdumpError(test.error, true)\n\t\t\t];\n\t\t} else {\n\t\t\toutput = [\n\t\t\t\t`# ${title}`,\n\t\t\t\tformat('%s %d - %s %s', passed, ++this.i, title, directive).trim()\n\t\t\t];\n\t\t}\n\n\t\treturn output.join('\\n');\n\t}\n\tunhandledError(err) {\n\t\tconst output = [\n\t\t\t`# ${err.message}`,\n\t\t\tformat('not ok %d - %s', ++this.i, err.message)\n\t\t];\n\t\t// AvaErrors don't have stack traces\n\t\tif (err.type !== 'exception' || err.name !== 'AvaError') {\n\t\t\toutput.push(dumpError(err, false));\n\t\t}\n\n\t\treturn output.join('\\n');\n\t}\n\tfinish(runStatus) {\n\t\tconst output = [\n\t\t\t'',\n\t\t\t'1..' + (runStatus.passCount + runStatus.failCount + runStatus.skipCount),\n\t\t\t'# tests ' + (runStatus.passCount + runStatus.failCount + runStatus.skipCount),\n\t\t\t'# pass ' + runStatus.passCount\n\t\t];\n\n\t\tif (runStatus.skipCount > 0) {\n\t\t\toutput.push(`# skip ${runStatus.skipCount}`);\n\t\t}\n\n\t\toutput.push('# fail ' + (runStatus.failCount + runStatus.rejectionCount + runStatus.exceptionCount), '');\n\n\t\treturn output.join('\\n');\n\t}\n\twrite(str) {\n\t\tconsole.log(str);\n\t}\n\tstdout(data) {\n\t\tprocess.stderr.write(data);\n\t}\n\tstderr(data) {\n\t\tthis.stdout(data);\n\t}\n}\n\nmodule.exports = TapReporter;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/logger.js":"'use strict';\nconst autoBind = require('auto-bind');\n\nclass Logger {\n\tconstructor(reporter) {\n\t\tthis.reporter = reporter;\n\t\tautoBind(this);\n\t}\n\tstart(runStatus) {\n\t\tif (!this.reporter.start) {\n\t\t\treturn;\n\t\t}\n\n\t\tthis.write(this.reporter.start(runStatus), runStatus);\n\t}\n\treset(runStatus) {\n\t\tif (!this.reporter.reset) {\n\t\t\treturn;\n\t\t}\n\n\t\tthis.write(this.reporter.reset(runStatus), runStatus);\n\t}\n\ttest(test, runStatus) {\n\t\tthis.write(this.reporter.test(test, runStatus), runStatus);\n\t}\n\tunhandledError(err, runStatus) {\n\t\tif (!this.reporter.unhandledError) {\n\t\t\treturn;\n\t\t}\n\n\t\tthis.write(this.reporter.unhandledError(err, runStatus), runStatus);\n\t}\n\tfinish(runStatus) {\n\t\tif (!this.reporter.finish) {\n\t\t\treturn;\n\t\t}\n\n\t\tthis.write(this.reporter.finish(runStatus), runStatus);\n\t}\n\tsection() {\n\t\tif (!this.reporter.section) {\n\t\t\treturn;\n\t\t}\n\n\t\tthis.write(this.reporter.section());\n\t}\n\tclear() {\n\t\tif (!this.reporter.clear) {\n\t\t\treturn false;\n\t\t}\n\n\t\tthis.write(this.reporter.clear());\n\t\treturn true;\n\t}\n\twrite(str, runStatus) {\n\t\tif (typeof str === 'undefined') {\n\t\t\treturn;\n\t\t}\n\n\t\tthis.reporter.write(str, runStatus);\n\t}\n\tstdout(data, runStatus) {\n\t\tif (!this.reporter.stdout) {\n\t\t\treturn;\n\t\t}\n\n\t\tthis.reporter.stdout(data, runStatus);\n\t}\n\tstderr(data, runStatus) {\n\t\tif (!this.reporter.stderr) {\n\t\t\treturn;\n\t\t}\n\n\t\tthis.reporter.stderr(data, runStatus);\n\t}\n\texit(code) {\n\t\tprocess.exit(code); // eslint-disable-line unicorn/no-process-exit\n\t}\n}\n\nmodule.exports = Logger;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/watcher.js":"'use strict';\nconst nodePath = require('path');\nconst debug = require('debug')('ava:watcher');\nconst diff = require('lodash.difference');\nconst chokidar = require('chokidar');\nconst flatten = require('arr-flatten');\nconst union = require('array-union');\nconst uniq = require('array-uniq');\nconst AvaFiles = require('./ava-files');\n\nfunction rethrowAsync(err) {\n\t// Don't swallow exceptions. Note that any\n\t// expected error should already have been logged\n\tsetImmediate(() => {\n\t\tthrow err;\n\t});\n}\n\nclass Debouncer {\n\tconstructor(watcher) {\n\t\tthis.watcher = watcher;\n\t\tthis.timer = null;\n\t\tthis.repeat = false;\n\t}\n\tdebounce() {\n\t\tif (this.timer) {\n\t\t\tthis.again = true;\n\t\t\treturn;\n\t\t}\n\n\t\tconst timer = setTimeout(() => {\n\t\t\tthis.watcher.busy.then(() => {\n\t\t\t\t// Do nothing if debouncing was canceled while waiting for the busy\n\t\t\t\t// promise to fulfil\n\t\t\t\tif (this.timer !== timer) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (this.again) {\n\t\t\t\t\tthis.timer = null;\n\t\t\t\t\tthis.again = false;\n\t\t\t\t\tthis.debounce();\n\t\t\t\t} else {\n\t\t\t\t\tthis.watcher.runAfterChanges();\n\t\t\t\t\tthis.timer = null;\n\t\t\t\t\tthis.again = false;\n\t\t\t\t}\n\t\t\t});\n\t\t}, 10);\n\n\t\tthis.timer = timer;\n\t}\n\tcancel() {\n\t\tif (this.timer) {\n\t\t\tclearTimeout(this.timer);\n\t\t\tthis.timer = null;\n\t\t\tthis.again = false;\n\t\t}\n\t}\n}\n\nclass TestDependency {\n\tconstructor(file, sources) {\n\t\tthis.file = file;\n\t\tthis.sources = sources;\n\t}\n\tcontains(source) {\n\t\treturn this.sources.indexOf(source) !== -1;\n\t}\n}\n\nclass Watcher {\n\tconstructor(logger, api, files, sources) {\n\t\tthis.debouncer = new Debouncer(this);\n\t\tthis.avaFiles = new AvaFiles({\n\t\t\tfiles,\n\t\t\tsources\n\t\t});\n\n\t\tthis.clearLogOnNextRun = true;\n\t\tthis.runVector = 0;\n\t\tthis.run = specificFiles => {\n\t\t\tif (this.runVector > 0) {\n\t\t\t\tconst cleared = this.clearLogOnNextRun && logger.clear();\n\t\t\t\tif (!cleared) {\n\t\t\t\t\tlogger.reset();\n\t\t\t\t\tlogger.section();\n\t\t\t\t}\n\t\t\t\tthis.clearLogOnNextRun = true;\n\n\t\t\t\tlogger.reset();\n\t\t\t\tlogger.start();\n\t\t\t}\n\n\t\t\tthis.runVector += 1;\n\n\t\t\tconst currentVector = this.runVector;\n\n\t\t\tlet runOnlyExclusive = false;\n\n\t\t\tif (specificFiles) {\n\t\t\t\tconst exclusiveFiles = specificFiles.filter(file => this.filesWithExclusiveTests.indexOf(file) !== -1);\n\n\t\t\t\trunOnlyExclusive = exclusiveFiles.length !== this.filesWithExclusiveTests.length;\n\n\t\t\t\tif (runOnlyExclusive) {\n\t\t\t\t\t// The test files that previously contained exclusive tests are always\n\t\t\t\t\t// run, together with the remaining specific files.\n\t\t\t\t\tconst remainingFiles = diff(specificFiles, exclusiveFiles);\n\t\t\t\t\tspecificFiles = this.filesWithExclusiveTests.concat(remainingFiles);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tthis.busy = api.run(specificFiles || files, {runOnlyExclusive})\n\t\t\t\t.then(runStatus => {\n\t\t\t\t\trunStatus.previousFailCount = this.sumPreviousFailures(currentVector);\n\t\t\t\t\tlogger.finish(runStatus);\n\n\t\t\t\t\tconst badCounts = runStatus.failCount + runStatus.rejectionCount + runStatus.exceptionCount;\n\t\t\t\t\tthis.clearLogOnNextRun = this.clearLogOnNextRun && badCounts === 0;\n\t\t\t\t})\n\t\t\t\t.catch(rethrowAsync);\n\t\t};\n\n\t\tthis.testDependencies = [];\n\t\tthis.trackTestDependencies(api, sources);\n\n\t\tthis.filesWithExclusiveTests = [];\n\t\tthis.trackExclusivity(api);\n\n\t\tthis.filesWithFailures = [];\n\t\tthis.trackFailures(api);\n\n\t\tthis.dirtyStates = {};\n\t\tthis.watchFiles();\n\t\tthis.rerunAll();\n\t}\n\twatchFiles() {\n\t\tconst patterns = this.avaFiles.getChokidarPatterns();\n\n\t\tchokidar.watch(patterns.paths, {\n\t\t\tignored: patterns.ignored,\n\t\t\tignoreInitial: true\n\t\t}).on('all', (event, path) => {\n\t\t\tif (event === 'add' || event === 'change' || event === 'unlink') {\n\t\t\t\tdebug('Detected %s of %s', event, path);\n\t\t\t\tthis.dirtyStates[path] = event;\n\t\t\t\tthis.debouncer.debounce();\n\t\t\t}\n\t\t});\n\t}\n\ttrackTestDependencies(api) {\n\t\tconst relative = absPath => nodePath.relative(process.cwd(), absPath);\n\n\t\tapi.on('test-run', runStatus => {\n\t\t\trunStatus.on('dependencies', (file, dependencies) => {\n\t\t\t\tconst sourceDeps = dependencies.map(relative).filter(this.avaFiles.isSource);\n\t\t\t\tthis.updateTestDependencies(file, sourceDeps);\n\t\t\t});\n\t\t});\n\t}\n\tupdateTestDependencies(file, sources) {\n\t\tif (sources.length === 0) {\n\t\t\tthis.testDependencies = this.testDependencies.filter(dep => dep.file !== file);\n\t\t\treturn;\n\t\t}\n\n\t\tconst isUpdate = this.testDependencies.some(dep => {\n\t\t\tif (dep.file !== file) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tdep.sources = sources;\n\n\t\t\treturn true;\n\t\t});\n\n\t\tif (!isUpdate) {\n\t\t\tthis.testDependencies.push(new TestDependency(file, sources));\n\t\t}\n\t}\n\ttrackExclusivity(api) {\n\t\tapi.on('stats', stats => {\n\t\t\tthis.updateExclusivity(stats.file, stats.hasExclusive);\n\t\t});\n\t}\n\tupdateExclusivity(file, hasExclusiveTests) {\n\t\tconst index = this.filesWithExclusiveTests.indexOf(file);\n\n\t\tif (hasExclusiveTests && index === -1) {\n\t\t\tthis.filesWithExclusiveTests.push(file);\n\t\t} else if (!hasExclusiveTests && index !== -1) {\n\t\t\tthis.filesWithExclusiveTests.splice(index, 1);\n\t\t}\n\t}\n\ttrackFailures(api) {\n\t\tapi.on('test-run', (runStatus, files) => {\n\t\t\tfiles.forEach(file => {\n\t\t\t\tthis.pruneFailures(nodePath.relative(process.cwd(), file));\n\t\t\t});\n\n\t\t\tconst currentVector = this.runVector;\n\t\t\trunStatus.on('error', err => {\n\t\t\t\tthis.countFailure(err.file, currentVector);\n\t\t\t});\n\t\t\trunStatus.on('test', result => {\n\t\t\t\tif (result.error) {\n\t\t\t\t\tthis.countFailure(result.file, currentVector);\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\t}\n\tpruneFailures(file) {\n\t\tthis.filesWithFailures = this.filesWithFailures.filter(state => state.file !== file);\n\t}\n\tcountFailure(file, vector) {\n\t\tconst isUpdate = this.filesWithFailures.some(state => {\n\t\t\tif (state.file !== file) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tstate.count++;\n\t\t\treturn true;\n\t\t});\n\n\t\tif (!isUpdate) {\n\t\t\tthis.filesWithFailures.push({\n\t\t\t\tfile,\n\t\t\t\tvector,\n\t\t\t\tcount: 1\n\t\t\t});\n\t\t}\n\t}\n\tsumPreviousFailures(beforeVector) {\n\t\tlet total = 0;\n\n\t\tthis.filesWithFailures.forEach(state => {\n\t\t\tif (state.vector < beforeVector) {\n\t\t\t\ttotal += state.count;\n\t\t\t}\n\t\t});\n\n\t\treturn total;\n\t}\n\tcleanUnlinkedTests(unlinkedTests) {\n\t\tunlinkedTests.forEach(testFile => {\n\t\t\tthis.updateTestDependencies(testFile, []);\n\t\t\tthis.updateExclusivity(testFile, false);\n\t\t\tthis.pruneFailures(testFile);\n\t\t});\n\t}\n\tobserveStdin(stdin) {\n\t\tstdin.resume();\n\t\tstdin.setEncoding('utf8');\n\n\t\tstdin.on('data', data => {\n\t\t\tdata = data.trim().toLowerCase();\n\t\t\tif (data !== 'r' && data !== 'rs') {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Cancel the debouncer, it might rerun specific tests whereas *all* tests\n\t\t\t// need to be rerun\n\t\t\tthis.debouncer.cancel();\n\t\t\tthis.busy.then(() => {\n\t\t\t\t// Cancel the debouncer again, it might have restarted while waiting for\n\t\t\t\t// the busy promise to fulfil\n\t\t\t\tthis.debouncer.cancel();\n\t\t\t\tthis.clearLogOnNextRun = false;\n\t\t\t\tthis.rerunAll();\n\t\t\t});\n\t\t});\n\t}\n\trerunAll() {\n\t\tthis.dirtyStates = {};\n\t\tthis.run();\n\t}\n\trunAfterChanges() {\n\t\tconst dirtyStates = this.dirtyStates;\n\t\tthis.dirtyStates = {};\n\n\t\tconst dirtyPaths = Object.keys(dirtyStates);\n\t\tconst dirtyTests = dirtyPaths.filter(this.avaFiles.isTest);\n\t\tconst dirtySources = diff(dirtyPaths, dirtyTests);\n\t\tconst addedOrChangedTests = dirtyTests.filter(path => dirtyStates[path] !== 'unlink');\n\t\tconst unlinkedTests = diff(dirtyTests, addedOrChangedTests);\n\n\t\tthis.cleanUnlinkedTests(unlinkedTests);\n\n\t\t// No need to rerun tests if the only change is that tests were deleted\n\t\tif (unlinkedTests.length === dirtyPaths.length) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (dirtySources.length === 0) {\n\t\t\t// Run any new or changed tests\n\t\t\tthis.run(addedOrChangedTests);\n\t\t\treturn;\n\t\t}\n\n\t\t// Try to find tests that depend on the changed source files\n\t\tconst testsBySource = dirtySources.map(path => {\n\t\t\treturn this.testDependencies.filter(dep => dep.contains(path)).map(dep => {\n\t\t\t\tdebug('%s is a dependency of %s', path, dep.file);\n\t\t\t\treturn dep.file;\n\t\t\t});\n\t\t}, this).filter(tests => tests.length > 0);\n\n\t\t// Rerun all tests if source files were changed that could not be traced to\n\t\t// specific tests\n\t\tif (testsBySource.length !== dirtySources.length) {\n\t\t\tdebug('Sources remain that cannot be traced to specific tests. Rerunning all tests');\n\t\t\tthis.run();\n\t\t\treturn;\n\t\t}\n\n\t\t// Run all affected tests\n\t\tthis.run(union(addedOrChangedTests, uniq(flatten(testsBySource))));\n\t}\n}\n\nmodule.exports = Watcher;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/.iron-node.js":"module.exports = {\n\tapp: {\n\t\topenDevToolsDetached: true,\n\t\thideMainWindow: true\n\t},\n\tworkSpaceDirectory: () => __dirname\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/profile.js":"'use strict';\n\n// Iron-node does not work with forked processes\n// This cli command will run a single file in the current process.\n// Intended to be used with iron-node for profiling purposes.\n\nconst path = require('path');\nconst EventEmitter = require('events');\nconst meow = require('meow');\nconst Promise = require('bluebird');\nconst pkgConf = require('pkg-conf');\nconst findCacheDir = require('find-cache-dir');\nconst uniqueTempDir = require('unique-temp-dir');\nconst arrify = require('arrify');\nconst resolveCwd = require('resolve-cwd');\nconst babelConfigHelper = require('./lib/babel-config');\nconst CachingPrecompiler = require('./lib/caching-precompiler');\nconst globals = require('./lib/globals');\n\nfunction resolveModules(modules) {\n\treturn arrify(modules).map(name => {\n\t\tconst modulePath = resolveCwd(name);\n\n\t\tif (modulePath === null) {\n\t\t\tthrow new Error(`Could not resolve required module '${name}'`);\n\t\t}\n\n\t\treturn modulePath;\n\t});\n}\n\n// Chrome gets upset when the `this` value is non-null for these functions\nglobals.setTimeout = setTimeout.bind(null);\nglobals.clearTimeout = clearTimeout.bind(null);\n\nPromise.longStackTraces();\n\nconst conf = pkgConf.sync('ava', {\n\tdefaults: {\n\t\tbabel: 'default'\n\t}\n});\n\n// Define a minimal set of options from the main CLI\nconst cli = meow(`\n\tUsage\n\t  $ iron-node node_modules/ava/profile.js <test-file>\n\n\tOptions\n\t  --fail-fast   Stop after first test failure\n\t  --serial, -s  Run tests serially\n\n`, {\n\tstring: [\n\t\t'_'\n\t],\n\tboolean: [\n\t\t'fail-fast',\n\t\t'verbose',\n\t\t'serial',\n\t\t'tap'\n\t],\n\tdefault: conf,\n\talias: {\n\t\ts: 'serial'\n\t}\n});\n\nif (cli.input.length !== 1) {\n\tthrow new Error('Specify a test file');\n}\n\nconst file = path.resolve(cli.input[0]);\nconst cacheDir = findCacheDir({\n\tname: 'ava',\n\tfiles: [file]\n}) || uniqueTempDir();\n\nbabelConfigHelper.build(process.cwd(), cacheDir, conf.babel, true)\n\t.then(result => {\n\t\tconst precompiler = new CachingPrecompiler({\n\t\t\tpath: cacheDir,\n\t\t\tgetBabelOptions: result.getOptions,\n\t\t\tbabelCacheKeys: result.cacheKeys\n\t\t});\n\n\t\tconst precompiled = {};\n\t\tprecompiled[file] = precompiler.precompileFile(file);\n\n\t\tconst opts = {\n\t\t\tfile,\n\t\t\tfailFast: cli.flags.failFast,\n\t\t\tserial: cli.flags.serial,\n\t\t\ttty: false,\n\t\t\tcacheDir,\n\t\t\tprecompiled,\n\t\t\trequire: resolveModules(conf.require)\n\t\t};\n\n\t\tconst events = new EventEmitter();\n\t\tlet uncaughtExceptionCount = 0;\n\n\t\t// Mock the behavior of a parent process\n\t\tprocess.channel = {ref() {}, unref() {}};\n\t\tprocess.send = data => {\n\t\t\tif (data && data.ava) {\n\t\t\t\tconst name = data.name.replace(/^ava-/, '');\n\n\t\t\t\tif (events.listeners(name).length > 0) {\n\t\t\t\t\tevents.emit(name, data.data);\n\t\t\t\t} else {\n\t\t\t\t\tconsole.log('UNHANDLED AVA EVENT:', name, data.data);\n\t\t\t\t}\n\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconsole.log('NON AVA EVENT:', data);\n\t\t};\n\n\t\tevents.on('test', data => {\n\t\t\tconsole.log('TEST:', data.title, data.error);\n\t\t});\n\n\t\tevents.on('results', data => {\n\t\t\tif (console.profileEnd) {\n\t\t\t\tconsole.profileEnd();\n\t\t\t}\n\n\t\t\tconsole.log('RESULTS:', data.stats);\n\n\t\t\tif (process.exit) {\n\t\t\t\tprocess.exit(data.stats.failCount + uncaughtExceptionCount); // eslint-disable-line unicorn/no-process-exit\n\t\t\t}\n\t\t});\n\n\t\tevents.on('stats', () => {\n\t\t\tsetImmediate(() => {\n\t\t\t\tprocess.emit('ava-run', {});\n\t\t\t});\n\t\t});\n\n\t\tevents.on('uncaughtException', data => {\n\t\t\tuncaughtExceptionCount++;\n\t\t\tlet stack = data && data.exception && data.exception.stack;\n\t\t\tstack = stack || data;\n\t\t\tconsole.log(stack);\n\t\t});\n\n\t\t// `test-worker` will read process.argv[2] for options\n\t\tprocess.argv[2] = JSON.stringify(opts);\n\t\tprocess.argv.length = 3;\n\n\t\tif (console.profile) {\n\t\t\tconsole.profile('AVA test-worker process');\n\t\t}\n\n\t\tsetImmediate(() => {\n\t\t\trequire('./lib/test-worker'); // eslint-disable-line import/no-unassigned-import\n\t\t});\n\t});\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/assert.js":"'use strict';\nconst coreAssert = require('core-assert');\nconst deepEqual = require('lodash.isequal');\nconst observableToPromise = require('observable-to-promise');\nconst isObservable = require('is-observable');\nconst isPromise = require('is-promise');\nconst jestDiff = require('jest-diff');\nconst enhanceAssert = require('./enhance-assert');\nconst formatAssertError = require('./format-assert-error');\n\nclass AssertionError extends Error {\n\tconstructor(opts) {\n\t\tsuper(opts.message || '');\n\t\tthis.name = 'AssertionError';\n\n\t\tthis.assertion = opts.assertion;\n\t\tthis.fixedSource = opts.fixedSource;\n\t\tthis.improperUsage = opts.improperUsage || false;\n\t\tthis.operator = opts.operator;\n\t\tthis.values = opts.values || [];\n\n\t\t// Reserved for power-assert statements\n\t\tthis.statements = [];\n\n\t\tif (opts.stack) {\n\t\t\tthis.stack = opts.stack;\n\t\t}\n\t}\n}\nexports.AssertionError = AssertionError;\n\nfunction getStack() {\n\tconst obj = {};\n\tError.captureStackTrace(obj, getStack);\n\treturn obj.stack;\n}\n\nfunction wrapAssertions(callbacks) {\n\tconst pass = callbacks.pass;\n\tconst pending = callbacks.pending;\n\tconst fail = callbacks.fail;\n\n\tconst noop = () => {};\n\tconst makeNoop = () => noop;\n\tconst makeRethrow = reason => () => {\n\t\tthrow reason;\n\t};\n\n\tconst assertions = {\n\t\tpass() {\n\t\t\tpass(this);\n\t\t},\n\n\t\tfail(message) {\n\t\t\tfail(this, new AssertionError({\n\t\t\t\tassertion: 'fail',\n\t\t\t\tmessage: message || 'Test failed via `t.fail()`'\n\t\t\t}));\n\t\t},\n\n\t\tis(actual, expected, message) {\n\t\t\tif (actual === expected) {\n\t\t\t\tpass(this);\n\t\t\t} else {\n\t\t\t\tconst diff = formatAssertError.formatDiff(actual, expected);\n\t\t\t\tconst values = diff ? [diff] : [\n\t\t\t\t\tformatAssertError.formatWithLabel('Actual:', actual),\n\t\t\t\t\tformatAssertError.formatWithLabel('Must be strictly equal to:', expected)\n\t\t\t\t];\n\n\t\t\t\tfail(this, new AssertionError({\n\t\t\t\t\tassertion: 'is',\n\t\t\t\t\tmessage,\n\t\t\t\t\toperator: '===',\n\t\t\t\t\tvalues\n\t\t\t\t}));\n\t\t\t}\n\t\t},\n\n\t\tnot(actual, expected, message) {\n\t\t\tif (actual === expected) {\n\t\t\t\tfail(this, new AssertionError({\n\t\t\t\t\tassertion: 'not',\n\t\t\t\t\tmessage,\n\t\t\t\t\toperator: '!==',\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Value is strictly equal:', actual)]\n\t\t\t\t}));\n\t\t\t} else {\n\t\t\t\tpass(this);\n\t\t\t}\n\t\t},\n\n\t\tdeepEqual(actual, expected, message) {\n\t\t\tif (deepEqual(actual, expected)) {\n\t\t\t\tpass(this);\n\t\t\t} else {\n\t\t\t\tconst diff = formatAssertError.formatDiff(actual, expected);\n\t\t\t\tconst values = diff ? [diff] : [\n\t\t\t\t\tformatAssertError.formatWithLabel('Actual:', actual),\n\t\t\t\t\tformatAssertError.formatWithLabel('Must be deeply equal to:', expected)\n\t\t\t\t];\n\n\t\t\t\tfail(this, new AssertionError({\n\t\t\t\t\tassertion: 'deepEqual',\n\t\t\t\t\tmessage,\n\t\t\t\t\tvalues\n\t\t\t\t}));\n\t\t\t}\n\t\t},\n\n\t\tnotDeepEqual(actual, expected, message) {\n\t\t\tif (deepEqual(actual, expected)) {\n\t\t\t\tfail(this, new AssertionError({\n\t\t\t\t\tassertion: 'notDeepEqual',\n\t\t\t\t\tmessage,\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Value is deeply equal:', actual)]\n\t\t\t\t}));\n\t\t\t} else {\n\t\t\t\tpass(this);\n\t\t\t}\n\t\t},\n\n\t\tthrows(fn, err, message) {\n\t\t\tlet promise;\n\t\t\tif (isPromise(fn)) {\n\t\t\t\tpromise = fn;\n\t\t\t} else if (isObservable(fn)) {\n\t\t\t\tpromise = observableToPromise(fn);\n\t\t\t} else if (typeof fn !== 'function') {\n\t\t\t\tfail(this, new AssertionError({\n\t\t\t\t\tassertion: 'throws',\n\t\t\t\t\timproperUsage: true,\n\t\t\t\t\tmessage: '`t.throws()` must be called with a function, Promise, or Observable',\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Called with:', fn)]\n\t\t\t\t}));\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tlet coreAssertThrowsErrorArg;\n\t\t\tif (typeof err === 'string') {\n\t\t\t\tconst expectedMessage = err;\n\t\t\t\tcoreAssertThrowsErrorArg = error => error.message === expectedMessage;\n\t\t\t} else {\n\t\t\t\t// Assume it's a constructor function or regular expression\n\t\t\t\tcoreAssertThrowsErrorArg = err;\n\t\t\t}\n\n\t\t\tconst test = (fn, stack) => {\n\t\t\t\tlet actual;\n\t\t\t\tlet threw = false;\n\t\t\t\ttry {\n\t\t\t\t\tcoreAssert.throws(() => {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tfn();\n\t\t\t\t\t\t} catch (err) {\n\t\t\t\t\t\t\tactual = err;\n\t\t\t\t\t\t\tthrew = true;\n\t\t\t\t\t\t\tthrow err;\n\t\t\t\t\t\t}\n\t\t\t\t\t}, coreAssertThrowsErrorArg);\n\t\t\t\t\treturn actual;\n\t\t\t\t} catch (err) {\n\t\t\t\t\tconst values = threw ?\n\t\t\t\t\t\t[formatAssertError.formatWithLabel('Threw unexpected exception:', actual)] :\n\t\t\t\t\t\tnull;\n\n\t\t\t\t\tthrow new AssertionError({\n\t\t\t\t\t\tassertion: 'throws',\n\t\t\t\t\t\tmessage,\n\t\t\t\t\t\tstack,\n\t\t\t\t\t\tvalues\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tif (promise) {\n\t\t\t\t// Record stack before it gets lost in the promise chain.\n\t\t\t\tconst stack = getStack();\n\t\t\t\tconst intermediate = promise.then(makeNoop, makeRethrow).then(fn => test(fn, stack));\n\t\t\t\tpending(this, intermediate);\n\t\t\t\t// Don't reject the returned promise, even if the assertion fails.\n\t\t\t\treturn intermediate.catch(noop);\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\tconst retval = test(fn);\n\t\t\t\tpass(this);\n\t\t\t\treturn retval;\n\t\t\t} catch (err) {\n\t\t\t\tfail(this, err);\n\t\t\t}\n\t\t},\n\n\t\tnotThrows(fn, message) {\n\t\t\tlet promise;\n\t\t\tif (isPromise(fn)) {\n\t\t\t\tpromise = fn;\n\t\t\t} else if (isObservable(fn)) {\n\t\t\t\tpromise = observableToPromise(fn);\n\t\t\t} else if (typeof fn !== 'function') {\n\t\t\t\tfail(this, new AssertionError({\n\t\t\t\t\tassertion: 'notThrows',\n\t\t\t\t\timproperUsage: true,\n\t\t\t\t\tmessage: '`t.notThrows()` must be called with a function, Promise, or Observable',\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Called with:', fn)]\n\t\t\t\t}));\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst test = (fn, stack) => {\n\t\t\t\ttry {\n\t\t\t\t\tcoreAssert.doesNotThrow(fn);\n\t\t\t\t} catch (err) {\n\t\t\t\t\tthrow new AssertionError({\n\t\t\t\t\t\tassertion: 'notThrows',\n\t\t\t\t\t\tmessage,\n\t\t\t\t\t\tstack,\n\t\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Threw:', err.actual)]\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tif (promise) {\n\t\t\t\t// Record stack before it gets lost in the promise chain.\n\t\t\t\tconst stack = getStack();\n\t\t\t\tconst intermediate = promise.then(noop, reason => test(makeRethrow(reason), stack));\n\t\t\t\tpending(this, intermediate);\n\t\t\t\t// Don't reject the returned promise, even if the assertion fails.\n\t\t\t\treturn intermediate.catch(noop);\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\ttest(fn);\n\t\t\t\tpass(this);\n\t\t\t} catch (err) {\n\t\t\t\tfail(this, err);\n\t\t\t}\n\t\t},\n\n\t\tifError(actual, message) {\n\t\t\tif (actual) {\n\t\t\t\tfail(this, new AssertionError({\n\t\t\t\t\tassertion: 'ifError',\n\t\t\t\t\tmessage,\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Error:', actual)]\n\t\t\t\t}));\n\t\t\t} else {\n\t\t\t\tpass(this);\n\t\t\t}\n\t\t},\n\n\t\tsnapshot(actual, message) {\n\t\t\tconst state = this._test.getSnapshotState();\n\t\t\tconst result = state.match(this.title, actual);\n\t\t\tif (result.pass) {\n\t\t\t\tpass(this);\n\t\t\t} else {\n\t\t\t\tconst diff = jestDiff(result.expected.trim(), result.actual.trim(), {expand: true})\n\t\t\t\t\t// Remove annotation\n\t\t\t\t\t.split('\\n')\n\t\t\t\t\t.slice(3)\n\t\t\t\t\t.join('\\n');\n\t\t\t\tfail(this, new AssertionError({\n\t\t\t\t\tassertion: 'snapshot',\n\t\t\t\t\tmessage: message || 'Did not match snapshot',\n\t\t\t\t\tvalues: [{label: 'Difference:', formatted: diff}]\n\t\t\t\t}));\n\t\t\t}\n\t\t}\n\t};\n\n\tconst enhancedAssertions = enhanceAssert(pass, fail, {\n\t\ttruthy(actual, message) {\n\t\t\tif (!actual) {\n\t\t\t\tthrow new AssertionError({\n\t\t\t\t\tassertion: 'truthy',\n\t\t\t\t\tmessage,\n\t\t\t\t\toperator: '!!',\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Value is not truthy:', actual)]\n\t\t\t\t});\n\t\t\t}\n\t\t},\n\n\t\tfalsy(actual, message) {\n\t\t\tif (actual) {\n\t\t\t\tthrow new AssertionError({\n\t\t\t\t\tassertion: 'falsy',\n\t\t\t\t\tmessage,\n\t\t\t\t\toperator: '!',\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Value is not falsy:', actual)]\n\t\t\t\t});\n\t\t\t}\n\t\t},\n\n\t\ttrue(actual, message) {\n\t\t\tif (actual !== true) {\n\t\t\t\tthrow new AssertionError({\n\t\t\t\t\tassertion: 'true',\n\t\t\t\t\tmessage,\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Value is not `true`:', actual)]\n\t\t\t\t});\n\t\t\t}\n\t\t},\n\n\t\tfalse(actual, message) {\n\t\t\tif (actual !== false) {\n\t\t\t\tthrow new AssertionError({\n\t\t\t\t\tassertion: 'false',\n\t\t\t\t\tmessage,\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Value is not `false`:', actual)]\n\t\t\t\t});\n\t\t\t}\n\t\t},\n\n\t\tregex(string, regex, message) {\n\t\t\tif (typeof string !== 'string') {\n\t\t\t\tthrow new AssertionError({\n\t\t\t\t\tassertion: 'regex',\n\t\t\t\t\timproperUsage: true,\n\t\t\t\t\tmessage: '`t.regex()` must be called with a string',\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Called with:', string)]\n\t\t\t\t});\n\t\t\t}\n\t\t\tif (!(regex instanceof RegExp)) {\n\t\t\t\tthrow new AssertionError({\n\t\t\t\t\tassertion: 'regex',\n\t\t\t\t\timproperUsage: true,\n\t\t\t\t\tmessage: '`t.regex()` must be called with a regular expression',\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Called with:', regex)]\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tif (!regex.test(string)) {\n\t\t\t\tthrow new AssertionError({\n\t\t\t\t\tassertion: 'regex',\n\t\t\t\t\tmessage,\n\t\t\t\t\tvalues: [\n\t\t\t\t\t\tformatAssertError.formatWithLabel('Value must match expression:', string),\n\t\t\t\t\t\tformatAssertError.formatWithLabel('Regular expression:', regex)\n\t\t\t\t\t]\n\t\t\t\t});\n\t\t\t}\n\t\t},\n\n\t\tnotRegex(string, regex, message) {\n\t\t\tif (typeof string !== 'string') {\n\t\t\t\tthrow new AssertionError({\n\t\t\t\t\tassertion: 'notRegex',\n\t\t\t\t\timproperUsage: true,\n\t\t\t\t\tmessage: '`t.notRegex()` must be called with a string',\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Called with:', string)]\n\t\t\t\t});\n\t\t\t}\n\t\t\tif (!(regex instanceof RegExp)) {\n\t\t\t\tthrow new AssertionError({\n\t\t\t\t\tassertion: 'notRegex',\n\t\t\t\t\timproperUsage: true,\n\t\t\t\t\tmessage: '`t.notRegex()` must be called with a regular expression',\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Called with:', regex)]\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tif (regex.test(string)) {\n\t\t\t\tthrow new AssertionError({\n\t\t\t\t\tassertion: 'notRegex',\n\t\t\t\t\tmessage,\n\t\t\t\t\tvalues: [\n\t\t\t\t\t\tformatAssertError.formatWithLabel('Value must not match expression:', string),\n\t\t\t\t\t\tformatAssertError.formatWithLabel('Regular expression:', regex)\n\t\t\t\t\t]\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t});\n\n\treturn Object.assign(assertions, enhancedAssertions);\n}\nexports.wrapAssertions = wrapAssertions;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/enhance-assert.js":"'use strict';\nconst dotProp = require('dot-prop');\nconst formatValue = require('./format-assert-error').formatValue;\n\n// When adding patterns, don't forget to add to\n// https://github.com/avajs/babel-preset-transform-test-files/blob/master/espower-patterns.json\n// Then release a new version of that preset and bump the SemVer range here.\nconst PATTERNS = [\n\t't.truthy(value, [message])',\n\t't.falsy(value, [message])',\n\t't.true(value, [message])',\n\t't.false(value, [message])',\n\t't.regex(contents, regex, [message])',\n\t't.notRegex(contents, regex, [message])'\n];\n\nconst isRangeMatch = (a, b) => {\n\treturn (a[0] === b[0] && a[1] === b[1]) ||\n\t\t(a[0] > b[0] && a[0] < b[1]) ||\n\t\t(a[1] > b[0] && a[1] < b[1]);\n};\n\nconst computeStatement = (tokens, range) => {\n\treturn tokens\n\t\t.filter(token => isRangeMatch(token.range, range))\n\t\t.map(token => token.value === undefined ? token.type.label : token.value)\n\t\t.join('');\n};\n\nconst getNode = (ast, path) => dotProp.get(ast, path.replace(/\\//g, '.'));\n\nconst formatter = context => {\n\tconst ast = JSON.parse(context.source.ast);\n\tconst tokens = JSON.parse(context.source.tokens);\n\tconst args = context.args[0].events;\n\n\treturn args\n\t\t.map(arg => {\n\t\t\tconst range = getNode(ast, arg.espath).range;\n\t\t\treturn [computeStatement(tokens, range), formatValue(arg.value, {maxDepth: 1})];\n\t\t})\n\t\t.reverse();\n};\n\nconst enhanceAssert = (pass, fail, assertions) => {\n\tconst empower = require('empower-core');\n\treturn empower(assertions, {\n\t\tdestructive: true,\n\t\tonError(event) {\n\t\t\tconst error = event.error;\n\t\t\tif (event.powerAssertContext) { // Context may be missing in internal tests.\n\t\t\t\terror.statements = formatter(event.powerAssertContext);\n\t\t\t}\n\t\t\tfail(this, error);\n\t\t},\n\t\tonSuccess() {\n\t\t\tpass(this);\n\t\t},\n\t\tpatterns: PATTERNS,\n\t\tbindReceiver: false\n\t});\n};\nmodule.exports = enhanceAssert;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/beautify-stack.js":"'use strict';\nconst StackUtils = require('stack-utils');\nconst cleanStack = require('clean-stack');\nconst debug = require('debug')('ava');\n\n// Ignore unimportant stack trace lines\nlet ignoreStackLines = [];\n\nconst avaInternals = /\\/ava\\/(?:lib\\/)?[\\w-]+\\.js:\\d+:\\d+\\)?$/;\nconst avaDependencies = /\\/node_modules\\/(?:bluebird|empower-core|(?:ava\\/node_modules\\/)?(?:babel-runtime|core-js))\\//;\n\nif (!debug.enabled) {\n\tignoreStackLines = StackUtils.nodeInternals();\n\tignoreStackLines.push(avaInternals);\n\tignoreStackLines.push(avaDependencies);\n}\n\nconst stackUtils = new StackUtils({internals: ignoreStackLines});\n\nmodule.exports = stack => {\n\tif (!stack) {\n\t\treturn '';\n\t}\n\n\t// Workaround for https://github.com/tapjs/stack-utils/issues/14\n\t// TODO: fix it in `stack-utils`\n\tstack = cleanStack(stack);\n\n\tconst title = stack.split('\\n')[0];\n\tconst lines = stackUtils\n\t\t.clean(stack)\n\t\t.split('\\n')\n\t\t.map(x => `    ${x}`)\n\t\t.join('\\n');\n\n\treturn `${title}\\n${lines}`;\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/concurrent.js":"'use strict';\n\nclass Concurrent {\n\tconstructor(runnables, bail) {\n\t\tif (!Array.isArray(runnables)) {\n\t\t\tthrow new TypeError('Expected an array of runnables');\n\t\t}\n\n\t\tthis.runnables = runnables;\n\t\tthis.bail = bail || false;\n\t}\n\n\trun() {\n\t\tlet allPassed = true;\n\n\t\tlet pending;\n\t\tlet rejectPending;\n\t\tlet resolvePending;\n\t\tconst allPromises = [];\n\t\tconst handlePromise = promise => {\n\t\t\tif (!pending) {\n\t\t\t\tpending = new Promise((resolve, reject) => {\n\t\t\t\t\trejectPending = reject;\n\t\t\t\t\tresolvePending = resolve;\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tallPromises.push(promise.then(passed => {\n\t\t\t\tif (!passed) {\n\t\t\t\t\tallPassed = false;\n\n\t\t\t\t\tif (this.bail) {\n\t\t\t\t\t\t// Stop if the test failed and bail mode is on.\n\t\t\t\t\t\tresolvePending();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}, rejectPending));\n\t\t};\n\n\t\tfor (const runnable of this.runnables) {\n\t\t\tconst passedOrPromise = runnable.run();\n\n\t\t\tif (!passedOrPromise) {\n\t\t\t\tif (this.bail) {\n\t\t\t\t\t// Stop if the test failed and bail mode is on.\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\n\t\t\t\tallPassed = false;\n\t\t\t} else if (passedOrPromise !== true) {\n\t\t\t\thandlePromise(passedOrPromise);\n\t\t\t}\n\t\t}\n\n\t\tif (pending) {\n\t\t\tPromise.all(allPromises).then(resolvePending);\n\t\t\treturn pending.then(() => allPassed);\n\t\t}\n\n\t\treturn allPassed;\n\t}\n}\n\nmodule.exports = Concurrent;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/runner.js":"'use strict';\nconst EventEmitter = require('events');\nconst path = require('path');\nconst Bluebird = require('bluebird');\nconst jestSnapshot = require('jest-snapshot');\nconst optionChain = require('option-chain');\nconst matcher = require('matcher');\nconst TestCollection = require('./test-collection');\nconst validateTest = require('./validate-test');\n\nconst chainableMethods = {\n\tdefaults: {\n\t\ttype: 'test',\n\t\tserial: false,\n\t\texclusive: false,\n\t\tskipped: false,\n\t\ttodo: false,\n\t\tfailing: false,\n\t\tcallback: false,\n\t\talways: false\n\t},\n\tchainableMethods: {\n\t\ttest: {},\n\t\tserial: {serial: true},\n\t\tbefore: {type: 'before'},\n\t\tafter: {type: 'after'},\n\t\tskip: {skipped: true},\n\t\ttodo: {todo: true},\n\t\tfailing: {failing: true},\n\t\tonly: {exclusive: true},\n\t\tbeforeEach: {type: 'beforeEach'},\n\t\tafterEach: {type: 'afterEach'},\n\t\tcb: {callback: true},\n\t\talways: {always: true}\n\t}\n};\n\nfunction wrapFunction(fn, args) {\n\treturn function (t) {\n\t\treturn fn.apply(this, [t].concat(args));\n\t};\n}\n\nclass Runner extends EventEmitter {\n\tconstructor(options) {\n\t\tsuper();\n\n\t\toptions = options || {};\n\n\t\tthis.file = options.file;\n\t\tthis.match = options.match || [];\n\t\tthis.serial = options.serial;\n\t\tthis.updateSnapshots = options.updateSnapshots;\n\n\t\tthis.hasStarted = false;\n\t\tthis.results = [];\n\t\tthis.snapshotState = null;\n\t\tthis.tests = new TestCollection({\n\t\t\tbail: options.bail,\n\t\t\tfailWithoutAssertions: options.failWithoutAssertions,\n\t\t\tgetSnapshotState: () => this.getSnapshotState()\n\t\t});\n\n\t\tthis.chain = optionChain(chainableMethods, (opts, args) => {\n\t\t\tlet title;\n\t\t\tlet fn;\n\t\t\tlet macroArgIndex;\n\n\t\t\tif (this.hasStarted) {\n\t\t\t\tthrow new Error('All tests and hooks must be declared synchronously in your ' +\n\t\t\t\t'test file, and cannot be nested within other tests or hooks.');\n\t\t\t}\n\n\t\t\tif (typeof args[0] === 'string') {\n\t\t\t\ttitle = args[0];\n\t\t\t\tfn = args[1];\n\t\t\t\tmacroArgIndex = 2;\n\t\t\t} else {\n\t\t\t\tfn = args[0];\n\t\t\t\ttitle = null;\n\t\t\t\tmacroArgIndex = 1;\n\t\t\t}\n\n\t\t\tif (this.serial) {\n\t\t\t\topts.serial = true;\n\t\t\t}\n\n\t\t\tif (args.length > macroArgIndex) {\n\t\t\t\targs = args.slice(macroArgIndex);\n\t\t\t} else {\n\t\t\t\targs = null;\n\t\t\t}\n\n\t\t\tif (Array.isArray(fn)) {\n\t\t\t\tfn.forEach(fn => {\n\t\t\t\t\tthis.addTest(title, opts, fn, args);\n\t\t\t\t});\n\t\t\t} else {\n\t\t\t\tthis.addTest(title, opts, fn, args);\n\t\t\t}\n\t\t});\n\t}\n\n\taddTest(title, metadata, fn, args) {\n\t\tif (args) {\n\t\t\tif (fn.title) {\n\t\t\t\ttitle = fn.title.apply(fn, [title || ''].concat(args));\n\t\t\t}\n\n\t\t\tfn = wrapFunction(fn, args);\n\t\t}\n\n\t\tif (metadata.type === 'test' && this.match.length > 0) {\n\t\t\tmetadata.exclusive = title !== null && matcher([title], this.match).length === 1;\n\t\t}\n\n\t\tconst validationError = validateTest(title, fn, metadata);\n\t\tif (validationError !== null) {\n\t\t\tthrow new TypeError(validationError);\n\t\t}\n\n\t\tthis.tests.add({\n\t\t\tmetadata,\n\t\t\tfn,\n\t\t\ttitle\n\t\t});\n\t}\n\n\taddTestResult(result) {\n\t\tconst test = result.result;\n\t\tconst props = {\n\t\t\tduration: test.duration,\n\t\t\ttitle: test.title,\n\t\t\terror: result.reason,\n\t\t\ttype: test.metadata.type,\n\t\t\tskip: test.metadata.skipped,\n\t\t\ttodo: test.metadata.todo,\n\t\t\tfailing: test.metadata.failing\n\t\t};\n\n\t\tthis.results.push(result);\n\t\tthis.emit('test', props);\n\t}\n\n\tbuildStats() {\n\t\tconst stats = {\n\t\t\tfailCount: 0,\n\t\t\tknownFailureCount: 0,\n\t\t\tpassCount: 0,\n\t\t\tskipCount: 0,\n\t\t\ttestCount: 0,\n\t\t\ttodoCount: 0\n\t\t};\n\n\t\tfor (const result of this.results) {\n\t\t\tif (!result.passed) {\n\t\t\t\t// Includes hooks\n\t\t\t\tstats.failCount++;\n\t\t\t}\n\n\t\t\tconst metadata = result.result.metadata;\n\t\t\tif (metadata.type === 'test') {\n\t\t\t\tstats.testCount++;\n\n\t\t\t\tif (metadata.skipped) {\n\t\t\t\t\tstats.skipCount++;\n\t\t\t\t} else if (metadata.todo) {\n\t\t\t\t\tstats.todoCount++;\n\t\t\t\t} else if (result.passed) {\n\t\t\t\t\tif (metadata.failing) {\n\t\t\t\t\t\tstats.knownFailureCount++;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstats.passCount++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn stats;\n\t}\n\n\tgetSnapshotState() {\n\t\tif (this.snapshotState) {\n\t\t\treturn this.snapshotState;\n\t\t}\n\n\t\tconst name = path.basename(this.file) + '.snap';\n\t\tconst dir = path.dirname(this.file);\n\n\t\tconst snapshotPath = path.join(dir, '__snapshots__', name);\n\t\tconst testPath = this.file;\n\t\tconst update = this.updateSnapshots;\n\n\t\tconst state = jestSnapshot.initializeSnapshotState(testPath, update, snapshotPath);\n\t\tthis.snapshotState = state;\n\t\treturn state;\n\t}\n\n\tsaveSnapshotState() {\n\t\tif (this.snapshotState) {\n\t\t\tthis.snapshotState.save(this.updateSnapshots);\n\t\t}\n\t}\n\n\trun(options) {\n\t\tif (options.runOnlyExclusive && !this.tests.hasExclusive) {\n\t\t\treturn Promise.resolve(null);\n\t\t}\n\n\t\tthis.hasStarted = true;\n\t\tthis.tests.on('test', result => {\n\t\t\tthis.addTestResult(result);\n\t\t});\n\t\treturn Bluebird.try(() => this.tests.build().run());\n\t}\n\tattributeLeakedError(err) {\n\t\treturn this.tests.attributeLeakedError(err);\n\t}\n}\n\nmodule.exports = Runner;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/test-collection.js":"'use strict';\nconst EventEmitter = require('events');\nconst fnName = require('fn-name');\nconst Concurrent = require('./concurrent');\nconst Sequence = require('./sequence');\nconst Test = require('./test');\n\nclass TestCollection extends EventEmitter {\n\tconstructor(options) {\n\t\tsuper();\n\n\t\tthis.bail = options.bail;\n\t\tthis.failWithoutAssertions = options.failWithoutAssertions;\n\t\tthis.getSnapshotState = options.getSnapshotState;\n\t\tthis.hasExclusive = false;\n\t\tthis.testCount = 0;\n\n\t\tthis.tests = {\n\t\t\tconcurrent: [],\n\t\t\tserial: []\n\t\t};\n\n\t\tthis.hooks = {\n\t\t\tbefore: [],\n\t\t\tbeforeEach: [],\n\t\t\tafter: [],\n\t\t\tafterAlways: [],\n\t\t\tafterEach: [],\n\t\t\tafterEachAlways: []\n\t\t};\n\n\t\tthis.pendingTestInstances = new Set();\n\n\t\tthis._emitTestResult = this._emitTestResult.bind(this);\n\t}\n\tadd(test) {\n\t\tconst metadata = test.metadata;\n\t\tconst type = metadata.type;\n\n\t\tif (!type) {\n\t\t\tthrow new Error('Test type must be specified');\n\t\t}\n\n\t\tif (!test.title && test.fn) {\n\t\t\ttest.title = fnName(test.fn);\n\t\t}\n\n\t\t// Workaround for Babel giving anonymous functions a name\n\t\tif (test.title === 'callee$0$0') {\n\t\t\ttest.title = null;\n\t\t}\n\n\t\tif (!test.title) {\n\t\t\tif (type === 'test') {\n\t\t\t\ttest.title = '[anonymous]';\n\t\t\t} else {\n\t\t\t\ttest.title = type;\n\t\t\t}\n\t\t}\n\n\t\tif (metadata.always && type !== 'after' && type !== 'afterEach') {\n\t\t\tthrow new Error('\"always\" can only be used with after and afterEach hooks');\n\t\t}\n\n\t\t// Add a hook\n\t\tif (type !== 'test') {\n\t\t\tif (metadata.exclusive) {\n\t\t\t\tthrow new Error(`\"only\" cannot be used with a ${type} hook`);\n\t\t\t}\n\n\t\t\tthis.hooks[type + (metadata.always ? 'Always' : '')].push(test);\n\t\t\treturn;\n\t\t}\n\n\t\tthis.testCount++;\n\n\t\t// Add `.only()` tests if `.only()` was used previously\n\t\tif (this.hasExclusive && !metadata.exclusive) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (metadata.exclusive && !this.hasExclusive) {\n\t\t\tthis.tests.concurrent = [];\n\t\t\tthis.tests.serial = [];\n\t\t\tthis.hasExclusive = true;\n\t\t}\n\n\t\tif (metadata.serial) {\n\t\t\tthis.tests.serial.push(test);\n\t\t} else {\n\t\t\tthis.tests.concurrent.push(test);\n\t\t}\n\t}\n\t_skippedTest(test) {\n\t\treturn {\n\t\t\trun: () => {\n\t\t\t\tthis._emitTestResult({\n\t\t\t\t\tpassed: true,\n\t\t\t\t\tresult: test\n\t\t\t\t});\n\n\t\t\t\treturn true;\n\t\t\t}\n\t\t};\n\t}\n\t_emitTestResult(result) {\n\t\tthis.pendingTestInstances.delete(result.result);\n\t\tthis.emit('test', result);\n\t}\n\t_buildHooks(hooks, testTitle, context) {\n\t\treturn hooks.map(hook => {\n\t\t\tconst test = this._buildHook(hook, testTitle, context);\n\n\t\t\tif (hook.metadata.skipped || hook.metadata.todo) {\n\t\t\t\treturn this._skippedTest(test);\n\t\t\t}\n\n\t\t\treturn test;\n\t\t});\n\t}\n\t_buildHook(hook, testTitle, contextRef) {\n\t\tlet title = hook.title;\n\n\t\tif (testTitle) {\n\t\t\ttitle += ` for ${testTitle}`;\n\t\t}\n\n\t\tif (!contextRef) {\n\t\t\tcontextRef = null;\n\t\t}\n\n\t\tconst test = new Test({\n\t\t\tcontextRef,\n\t\t\tfailWithoutAssertions: false,\n\t\t\tfn: hook.fn,\n\t\t\tgetSnapshotState: this.getSnapshotState,\n\t\t\tmetadata: hook.metadata,\n\t\t\tonResult: this._emitTestResult,\n\t\t\ttitle\n\t\t});\n\t\tthis.pendingTestInstances.add(test);\n\t\treturn test;\n\t}\n\t_buildTest(test, contextRef) {\n\t\tif (!contextRef) {\n\t\t\tcontextRef = null;\n\t\t}\n\n\t\ttest = new Test({\n\t\t\tcontextRef,\n\t\t\tfailWithoutAssertions: this.failWithoutAssertions,\n\t\t\tfn: test.fn,\n\t\t\tgetSnapshotState: this.getSnapshotState,\n\t\t\tmetadata: test.metadata,\n\t\t\tonResult: this._emitTestResult,\n\t\t\ttitle: test.title\n\t\t});\n\t\tthis.pendingTestInstances.add(test);\n\t\treturn test;\n\t}\n\t_buildTestWithHooks(test) {\n\t\tif (test.metadata.skipped || test.metadata.todo) {\n\t\t\treturn new Sequence([this._skippedTest(this._buildTest(test))], true);\n\t\t}\n\n\t\tconst context = {context: {}};\n\n\t\tconst beforeHooks = this._buildHooks(this.hooks.beforeEach, test.title, context);\n\t\tconst afterHooks = this._buildHooks(this.hooks.afterEach, test.title, context);\n\n\t\tlet sequence = new Sequence([].concat(beforeHooks, this._buildTest(test, context), afterHooks), true);\n\t\tif (this.hooks.afterEachAlways.length > 0) {\n\t\t\tconst afterAlwaysHooks = new Sequence(this._buildHooks(this.hooks.afterEachAlways, test.title, context));\n\t\t\tsequence = new Sequence([sequence, afterAlwaysHooks], false);\n\t\t}\n\t\treturn sequence;\n\t}\n\t_buildTests(tests) {\n\t\treturn tests.map(test => this._buildTestWithHooks(test));\n\t}\n\tbuild() {\n\t\tconst beforeHooks = new Sequence(this._buildHooks(this.hooks.before));\n\t\tconst afterHooks = new Sequence(this._buildHooks(this.hooks.after));\n\n\t\tconst serialTests = new Sequence(this._buildTests(this.tests.serial), this.bail);\n\t\tconst concurrentTests = new Concurrent(this._buildTests(this.tests.concurrent), this.bail);\n\t\tconst allTests = new Sequence([serialTests, concurrentTests]);\n\n\t\tlet finalTests = new Sequence([beforeHooks, allTests, afterHooks], true);\n\t\tif (this.hooks.afterAlways.length > 0) {\n\t\t\tconst afterAlwaysHooks = new Sequence(this._buildHooks(this.hooks.afterAlways));\n\t\t\tfinalTests = new Sequence([finalTests, afterAlwaysHooks], false);\n\t\t}\n\t\treturn finalTests;\n\t}\n\tattributeLeakedError(err) {\n\t\tfor (const test of this.pendingTestInstances) {\n\t\t\tif (test.attributeLeakedError(err)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n}\n\nmodule.exports = TestCollection;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/sequence.js":"'use strict';\n\nconst beforeExitSubscribers = new Set();\nconst beforeExitHandler = () => {\n\tfor (const subscriber of beforeExitSubscribers) {\n\t\tsubscriber();\n\t}\n};\nconst onBeforeExit = subscriber => {\n\tif (beforeExitSubscribers.size === 0) {\n\t\t// Only listen for the event once, no matter how many Sequences are run\n\t\t// concurrently.\n\t\tprocess.on('beforeExit', beforeExitHandler);\n\t}\n\n\tbeforeExitSubscribers.add(subscriber);\n\treturn {\n\t\tdispose() {\n\t\t\tbeforeExitSubscribers.delete(subscriber);\n\t\t\tif (beforeExitSubscribers.size === 0) {\n\t\t\t\tprocess.removeListener('beforeExit', beforeExitHandler);\n\t\t\t}\n\t\t}\n\t};\n};\n\nclass Sequence {\n\tconstructor(runnables, bail) {\n\t\tif (!Array.isArray(runnables)) {\n\t\t\tthrow new TypeError('Expected an array of runnables');\n\t\t}\n\n\t\tthis.runnables = runnables;\n\t\tthis.bail = bail || false;\n\t}\n\n\trun() {\n\t\tconst iterator = this.runnables[Symbol.iterator]();\n\n\t\tlet activeRunnable;\n\t\tconst beforeExit = onBeforeExit(() => {\n\t\t\tif (activeRunnable.finishDueToInactivity) {\n\t\t\t\tactiveRunnable.finishDueToInactivity();\n\t\t\t}\n\t\t});\n\n\t\tlet allPassed = true;\n\t\tconst finish = () => {\n\t\t\tbeforeExit.dispose();\n\t\t\treturn allPassed;\n\t\t};\n\n\t\tconst runNext = () => {\n\t\t\tlet promise;\n\n\t\t\tfor (let next = iterator.next(); !next.done; next = iterator.next()) {\n\t\t\t\tactiveRunnable = next.value;\n\t\t\t\tconst passedOrPromise = activeRunnable.run();\n\t\t\t\tif (!passedOrPromise) {\n\t\t\t\t\tallPassed = false;\n\n\t\t\t\t\tif (this.bail) {\n\t\t\t\t\t\t// Stop if the test failed and bail mode is on.\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t} else if (passedOrPromise !== true) {\n\t\t\t\t\tpromise = passedOrPromise;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (!promise) {\n\t\t\t\treturn finish();\n\t\t\t}\n\n\t\t\treturn promise.then(passed => {\n\t\t\t\tif (!passed) {\n\t\t\t\t\tallPassed = false;\n\n\t\t\t\t\tif (this.bail) {\n\t\t\t\t\t\t// Stop if the test failed and bail mode is on.\n\t\t\t\t\t\treturn finish();\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\treturn runNext();\n\t\t\t});\n\t\t};\n\n\t\treturn runNext();\n\t}\n}\n\nmodule.exports = Sequence;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/test.js":"'use strict';\nconst isGeneratorFn = require('is-generator-fn');\nconst co = require('co-with-promise');\nconst observableToPromise = require('observable-to-promise');\nconst isPromise = require('is-promise');\nconst isObservable = require('is-observable');\nconst plur = require('plur');\nconst assert = require('./assert');\nconst formatAssertError = require('./format-assert-error');\nconst globals = require('./globals');\n\nclass SkipApi {\n\tconstructor(test) {\n\t\tthis._test = test;\n\t}\n}\n\nconst captureStack = start => {\n\tconst limitBefore = Error.stackTraceLimit;\n\tError.stackTraceLimit = 1;\n\tconst obj = {};\n\tError.captureStackTrace(obj, start);\n\tError.stackTraceLimit = limitBefore;\n\treturn obj.stack;\n};\n\nclass ExecutionContext {\n\tconstructor(test) {\n\t\tthis._test = test;\n\t\tthis.skip = new SkipApi(test);\n\t}\n\n\tplan(ct) {\n\t\tthis._test.plan(ct, captureStack(this.plan));\n\t}\n\n\tget end() {\n\t\tconst end = this._test.bindEndCallback();\n\t\tconst endFn = err => end(err, captureStack(endFn));\n\t\treturn endFn;\n\t}\n\n\tget title() {\n\t\treturn this._test.title;\n\t}\n\n\tget context() {\n\t\tconst contextRef = this._test.contextRef;\n\t\treturn contextRef && contextRef.context;\n\t}\n\n\tset context(context) {\n\t\tconst contextRef = this._test.contextRef;\n\n\t\tif (!contextRef) {\n\t\t\tthis._test.saveFirstError(new Error(`\\`t.context\\` is not available in ${this._test.metadata.type} tests`));\n\t\t\treturn;\n\t\t}\n\n\t\tcontextRef.context = context;\n\t}\n\n\t_throwsArgStart(assertion, file, line) {\n\t\tthis._test.trackThrows({assertion, file, line});\n\t}\n\t_throwsArgEnd() {\n\t\tthis._test.trackThrows(null);\n\t}\n}\nObject.defineProperty(ExecutionContext.prototype, 'context', {enumerable: true});\n\n{\n\tconst assertions = assert.wrapAssertions({\n\t\tpass(executionContext) {\n\t\t\texecutionContext._test.countPassedAssertion();\n\t\t},\n\n\t\tpending(executionContext, promise) {\n\t\t\texecutionContext._test.addPendingAssertion(promise);\n\t\t},\n\n\t\tfail(executionContext, error) {\n\t\t\texecutionContext._test.addFailedAssertion(error);\n\t\t}\n\t});\n\tObject.assign(ExecutionContext.prototype, assertions);\n\n\tfunction skipFn() {\n\t\tthis._test.countPassedAssertion();\n\t}\n\tObject.keys(assertions).forEach(el => {\n\t\tSkipApi.prototype[el] = skipFn;\n\t});\n}\n\nclass Test {\n\tconstructor(options) {\n\t\tthis.contextRef = options.contextRef;\n\t\tthis.failWithoutAssertions = options.failWithoutAssertions;\n\t\tthis.fn = isGeneratorFn(options.fn) ? co.wrap(options.fn) : options.fn;\n\t\tthis.getSnapshotState = options.getSnapshotState;\n\t\tthis.metadata = options.metadata;\n\t\tthis.onResult = options.onResult;\n\t\tthis.title = options.title;\n\n\t\tthis.assertCount = 0;\n\t\tthis.assertError = undefined;\n\t\tthis.calledEnd = false;\n\t\tthis.duration = null;\n\t\tthis.endCallbackFinisher = null;\n\t\tthis.finishDueToAttributedError = null;\n\t\tthis.finishDueToInactivity = null;\n\t\tthis.finishing = false;\n\t\tthis.pendingAssertionCount = 0;\n\t\tthis.pendingThrowsAssertion = null;\n\t\tthis.planCount = null;\n\t\tthis.startedAt = 0;\n\t}\n\n\tbindEndCallback() {\n\t\tif (this.metadata.callback) {\n\t\t\treturn (err, stack) => {\n\t\t\t\tthis.endCallback(err, stack);\n\t\t\t};\n\t\t}\n\n\t\tthrow new Error('`t.end()`` is not supported in this context. To use `t.end()` as a callback, you must use \"callback mode\" via `test.cb(testName, fn)`');\n\t}\n\n\tendCallback(err, stack) {\n\t\tif (this.calledEnd) {\n\t\t\tthis.saveFirstError(new Error('`t.end()` called more than once'));\n\t\t\treturn;\n\t\t}\n\t\tthis.calledEnd = true;\n\n\t\tif (err) {\n\t\t\tthis.saveFirstError(new assert.AssertionError({\n\t\t\t\tactual: err,\n\t\t\t\tmessage: 'Callback called with an error',\n\t\t\t\tstack,\n\t\t\t\tvalues: [formatAssertError.formatWithLabel('Error:', err)]\n\t\t\t}));\n\t\t}\n\n\t\tif (this.endCallbackFinisher) {\n\t\t\tthis.endCallbackFinisher();\n\t\t}\n\t}\n\n\tcreateExecutionContext() {\n\t\treturn new ExecutionContext(this);\n\t}\n\n\tcountPassedAssertion() {\n\t\tif (this.finishing) {\n\t\t\tthis.saveFirstError(new Error('Assertion passed, but test has already finished'));\n\t\t}\n\n\t\tthis.assertCount++;\n\t}\n\n\taddPendingAssertion(promise) {\n\t\tif (this.finishing) {\n\t\t\tthis.saveFirstError(new Error('Assertion passed, but test has already finished'));\n\t\t}\n\n\t\tthis.assertCount++;\n\t\tthis.pendingAssertionCount++;\n\t\tpromise\n\t\t\t.catch(err => this.saveFirstError(err))\n\t\t\t.then(() => this.pendingAssertionCount--);\n\t}\n\n\taddFailedAssertion(error) {\n\t\tif (this.finishing) {\n\t\t\tthis.saveFirstError(new Error('Assertion failed, but test has already finished'));\n\t\t}\n\n\t\tthis.assertCount++;\n\t\tthis.saveFirstError(error);\n\t}\n\n\tsaveFirstError(err) {\n\t\tif (!this.assertError) {\n\t\t\tthis.assertError = err;\n\t\t}\n\t}\n\n\tplan(count, planStack) {\n\t\tif (typeof count !== 'number') {\n\t\t\tthrow new TypeError('Expected a number');\n\t\t}\n\n\t\tthis.planCount = count;\n\n\t\t// In case the `planCount` doesn't match `assertCount, we need the stack of\n\t\t// this function to throw with a useful stack.\n\t\tthis.planStack = planStack;\n\t}\n\n\tverifyPlan() {\n\t\tif (!this.assertError && this.planCount !== null && this.planCount !== this.assertCount) {\n\t\t\tthis.saveFirstError(new assert.AssertionError({\n\t\t\t\tassertion: 'plan',\n\t\t\t\tmessage: `Planned for ${this.planCount} ${plur('assertion', this.planCount)}, but got ${this.assertCount}.`,\n\t\t\t\toperator: '===',\n\t\t\t\tstack: this.planStack\n\t\t\t}));\n\t\t}\n\t}\n\n\tverifyAssertions() {\n\t\tif (!this.assertError) {\n\t\t\tif (this.failWithoutAssertions && !this.calledEnd && this.planCount === null && this.assertCount === 0) {\n\t\t\t\tthis.saveFirstError(new Error('Test finished without running any assertions'));\n\t\t\t} else if (this.pendingAssertionCount > 0) {\n\t\t\t\tthis.saveFirstError(new Error('Test finished, but an assertion is still pending'));\n\t\t\t}\n\t\t}\n\t}\n\n\ttrackThrows(pending) {\n\t\tthis.pendingThrowsAssertion = pending;\n\t}\n\n\tdetectImproperThrows(err) {\n\t\tif (!this.pendingThrowsAssertion) {\n\t\t\treturn false;\n\t\t}\n\n\t\tconst pending = this.pendingThrowsAssertion;\n\t\tthis.pendingThrowsAssertion = null;\n\n\t\tconst values = [];\n\t\tif (err) {\n\t\t\tvalues.push(formatAssertError.formatWithLabel(`The following error was thrown, possibly before \\`t.${pending.assertion}()\\` could be called:`, err));\n\t\t}\n\n\t\tthis.saveFirstError(new assert.AssertionError({\n\t\t\tassertion: pending.assertion,\n\t\t\tfixedSource: {file: pending.file, line: pending.line},\n\t\t\timproperUsage: true,\n\t\t\tmessage: `Improper usage of \\`t.${pending.assertion}()\\` detected`,\n\t\t\tstack: err instanceof Error && err.stack,\n\t\t\tvalues\n\t\t}));\n\t\treturn true;\n\t}\n\n\twaitForPendingThrowsAssertion() {\n\t\treturn new Promise(resolve => {\n\t\t\tthis.finishDueToAttributedError = () => {\n\t\t\t\tresolve(this.finishPromised());\n\t\t\t};\n\n\t\t\tthis.finishDueToInactivity = () => {\n\t\t\t\tthis.detectImproperThrows();\n\t\t\t\tresolve(this.finishPromised());\n\t\t\t};\n\n\t\t\t// Wait up to a second to see if an error can be attributed to the\n\t\t\t// pending assertion.\n\t\t\tglobals.setTimeout(() => this.finishDueToInactivity(), 1000).unref();\n\t\t});\n\t}\n\n\tattributeLeakedError(err) {\n\t\tif (!this.detectImproperThrows(err)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tthis.finishDueToAttributedError();\n\t\treturn true;\n\t}\n\n\tcallFn() {\n\t\ttry {\n\t\t\treturn {\n\t\t\t\tok: true,\n\t\t\t\tretval: this.fn(this.createExecutionContext())\n\t\t\t};\n\t\t} catch (err) {\n\t\t\treturn {\n\t\t\t\tok: false,\n\t\t\t\terror: err\n\t\t\t};\n\t\t}\n\t}\n\n\trun() {\n\t\tthis.startedAt = globals.now();\n\n\t\tconst result = this.callFn();\n\t\tif (!result.ok) {\n\t\t\tif (!this.detectImproperThrows(result.error)) {\n\t\t\t\tthis.saveFirstError(new assert.AssertionError({\n\t\t\t\t\tmessage: 'Error thrown in test',\n\t\t\t\t\tstack: result.error instanceof Error && result.error.stack,\n\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Error:', result.error)]\n\t\t\t\t}));\n\t\t\t}\n\t\t\treturn this.finish();\n\t\t}\n\n\t\tconst returnedObservable = isObservable(result.retval);\n\t\tconst returnedPromise = isPromise(result.retval);\n\n\t\tlet promise;\n\t\tif (returnedObservable) {\n\t\t\tpromise = observableToPromise(result.retval);\n\t\t} else if (returnedPromise) {\n\t\t\t// `retval` can be any thenable, so convert to a proper promise.\n\t\t\tpromise = Promise.resolve(result.retval);\n\t\t}\n\n\t\tif (this.metadata.callback) {\n\t\t\tif (returnedObservable || returnedPromise) {\n\t\t\t\tconst asyncType = returnedObservable ? 'observables' : 'promises';\n\t\t\t\tthis.saveFirstError(new Error(`Do not return ${asyncType} from tests declared via \\`test.cb(...)\\`, if you want to return a promise simply declare the test via \\`test(...)\\``));\n\t\t\t\treturn this.finish();\n\t\t\t}\n\n\t\t\tif (this.calledEnd) {\n\t\t\t\treturn this.finish();\n\t\t\t}\n\n\t\t\treturn new Promise(resolve => {\n\t\t\t\tthis.endCallbackFinisher = () => {\n\t\t\t\t\tresolve(this.finishPromised());\n\t\t\t\t};\n\n\t\t\t\tthis.finishDueToAttributedError = () => {\n\t\t\t\t\tresolve(this.finishPromised());\n\t\t\t\t};\n\n\t\t\t\tthis.finishDueToInactivity = () => {\n\t\t\t\t\tthis.saveFirstError(new Error('`t.end()` was never called'));\n\t\t\t\t\tresolve(this.finishPromised());\n\t\t\t\t};\n\t\t\t});\n\t\t}\n\n\t\tif (promise) {\n\t\t\treturn new Promise(resolve => {\n\t\t\t\tthis.finishDueToAttributedError = () => {\n\t\t\t\t\tresolve(this.finishPromised());\n\t\t\t\t};\n\n\t\t\t\tthis.finishDueToInactivity = () => {\n\t\t\t\t\tconst err = returnedObservable ?\n\t\t\t\t\t\tnew Error('Observable returned by test never completed') :\n\t\t\t\t\t\tnew Error('Promise returned by test never resolved');\n\t\t\t\t\tthis.saveFirstError(err);\n\t\t\t\t\tresolve(this.finishPromised());\n\t\t\t\t};\n\n\t\t\t\tpromise\n\t\t\t\t\t.catch(err => {\n\t\t\t\t\t\tif (!this.detectImproperThrows(err)) {\n\t\t\t\t\t\t\tthis.saveFirstError(new assert.AssertionError({\n\t\t\t\t\t\t\t\tmessage: 'Rejected promise returned by test',\n\t\t\t\t\t\t\t\tstack: err instanceof Error && err.stack,\n\t\t\t\t\t\t\t\tvalues: [formatAssertError.formatWithLabel('Rejection reason:', err)]\n\t\t\t\t\t\t\t}));\n\t\t\t\t\t\t}\n\t\t\t\t\t})\n\t\t\t\t\t.then(() => resolve(this.finishPromised()));\n\t\t\t});\n\t\t}\n\n\t\treturn this.finish();\n\t}\n\n\tfinish() {\n\t\tthis.finishing = true;\n\n\t\tif (!this.assertError && this.pendingThrowsAssertion) {\n\t\t\treturn this.waitForPendingThrowsAssertion();\n\t\t}\n\n\t\tthis.verifyPlan();\n\t\tthis.verifyAssertions();\n\n\t\tthis.duration = globals.now() - this.startedAt;\n\n\t\tlet reason = this.assertError;\n\t\tlet passed = !reason;\n\n\t\tif (this.metadata.failing) {\n\t\t\tpassed = !passed;\n\n\t\t\tif (passed) {\n\t\t\t\treason = undefined;\n\t\t\t} else {\n\t\t\t\treason = new Error('Test was expected to fail, but succeeded, you should stop marking the test as failing');\n\t\t\t}\n\t\t}\n\n\t\tthis.onResult({\n\t\t\tpassed,\n\t\t\tresult: this,\n\t\t\treason\n\t\t});\n\n\t\treturn passed;\n\t}\n\n\tfinishPromised() {\n\t\treturn new Promise(resolve => {\n\t\t\tresolve(this.finish());\n\t\t});\n\t}\n}\n\nmodule.exports = Test;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/validate-test.js":"'use strict';\n\nfunction validate(title, fn, metadata) {\n\tif (metadata.type !== 'test') {\n\t\tif (metadata.exclusive) {\n\t\t\treturn '`only` is only for tests and cannot be used with hooks';\n\t\t}\n\n\t\tif (metadata.failing) {\n\t\t\treturn '`failing` is only for tests and cannot be used with hooks';\n\t\t}\n\n\t\tif (metadata.todo) {\n\t\t\treturn '`todo` is only for documentation of future tests and cannot be used with hooks';\n\t\t}\n\t}\n\n\tif (metadata.todo) {\n\t\tif (typeof fn === 'function') {\n\t\t\treturn '`todo` tests are not allowed to have an implementation. Use ' +\n\t\t\t'`test.skip()` for tests with an implementation.';\n\t\t}\n\n\t\tif (typeof title !== 'string') {\n\t\t\treturn '`todo` tests require a title';\n\t\t}\n\n\t\tif (metadata.skipped || metadata.failing || metadata.exclusive) {\n\t\t\treturn '`todo` tests are just for documentation and cannot be used with `skip`, `only`, or `failing`';\n\t\t}\n\t} else if (typeof fn !== 'function') {\n\t\treturn 'Expected an implementation. Use `test.todo()` for tests without an implementation.';\n\t}\n\n\tif (metadata.always) {\n\t\tif (!(metadata.type === 'after' || metadata.type === 'afterEach')) {\n\t\t\treturn '`always` can only be used with `after` and `afterEach`';\n\t\t}\n\t}\n\n\tif (metadata.skipped && metadata.exclusive) {\n\t\treturn '`only` tests cannot be skipped';\n\t}\n\n\treturn null;\n}\n\nmodule.exports = validate;\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/lib/serialize-error.js":"'use strict';\nconst path = require('path');\nconst cleanYamlObject = require('clean-yaml-object');\nconst StackUtils = require('stack-utils');\nconst assert = require('./assert');\nconst beautifyStack = require('./beautify-stack');\nconst extractStack = require('./extract-stack');\n\nfunction isAvaAssertionError(source) {\n\treturn source instanceof assert.AssertionError;\n}\n\nfunction filter(propertyName, isRoot) {\n\treturn !isRoot || (propertyName !== 'message' && propertyName !== 'name' && propertyName !== 'stack');\n}\n\nconst stackUtils = new StackUtils();\nfunction extractSource(stack) {\n\tif (!stack) {\n\t\treturn null;\n\t}\n\n\tconst firstStackLine = extractStack(stack).split('\\n')[0];\n\treturn stackUtils.parseLine(firstStackLine);\n}\nfunction buildSource(source) {\n\tif (!source) {\n\t\treturn null;\n\t}\n\n\t// Assume the CWD is the project directory. This holds since this function\n\t// is only called in test workers, which are created with their working\n\t// directory set to the project directory.\n\tconst projectDir = process.cwd();\n\n\tconst file = path.resolve(projectDir, source.file.trim());\n\tconst rel = path.relative(projectDir, file);\n\n\tconst isWithinProject = rel.split(path.sep)[0] !== '..';\n\tconst isDependency = isWithinProject && path.dirname(rel).split(path.sep).indexOf('node_modules') > -1;\n\n\treturn {\n\t\tisDependency,\n\t\tisWithinProject,\n\t\tfile,\n\t\tline: source.line\n\t};\n}\n\nmodule.exports = error => {\n\tconst stack = typeof error.stack === 'string' ?\n\t\tbeautifyStack(error.stack) :\n\t\tnull;\n\n\tconst retval = {\n\t\tavaAssertionError: isAvaAssertionError(error),\n\t\tsource: buildSource(extractSource(stack))\n\t};\n\tif (stack) {\n\t\tretval.stack = stack;\n\t}\n\n\tif (retval.avaAssertionError) {\n\t\tretval.improperUsage = error.improperUsage;\n\t\tretval.message = error.message;\n\t\tretval.name = error.name;\n\t\tretval.statements = error.statements;\n\t\tretval.values = error.values;\n\n\t\tif (error.fixedSource) {\n\t\t\tconst source = buildSource(error.fixedSource);\n\t\t\tif (source) {\n\t\t\t\tretval.source = source;\n\t\t\t}\n\t\t}\n\n\t\tif (error.assertion) {\n\t\t\tretval.assertion = error.assertion;\n\t\t}\n\t\tif (error.operator) {\n\t\t\tretval.operator = error.operator;\n\t\t}\n\t} else {\n\t\tretval.object = cleanYamlObject(error, filter); // Cleanly copy non-standard properties\n\t\tif (typeof error.message === 'string') {\n\t\t\tretval.message = error.message;\n\t\t}\n\t\tif (typeof error.name === 'string') {\n\t\t\tretval.name = error.name;\n\t\t}\n\t}\n\n\treturn retval;\n};\n","/home/travis/build/npmtest/node-npmtest-ava/node_modules/ava/types/make.js":"'use strict';\n\n// TypeScript definitions are generated here.\n// AVA allows chaining of function names, like `test.after.cb.always`.\n// The order of these names is not important.\n// Writing these definitions by hand is hard. Because of chaining,\n// the number of combinations grows fast (2^n). To reduce this number,\n// illegal combinations are filtered out in `verify`.\n// The order of the options is not important. We could generate full\n// definitions for each possible order, but that would give a very big\n// output. Instead, we write an alias for different orders. For instance,\n// `after.cb` is fully written, and `cb.after` is emitted as an alias\n// using `typeof after.cb`.\n\nconst path = require('path');\nconst fs = require('fs');\nconst isArraySorted = require('is-array-sorted');\nconst Runner = require('../lib/runner');\n\nconst arrayHas = parts => part => parts.indexOf(part) !== -1;\n\nconst base = fs.readFileSync(path.join(__dirname, 'base.d.ts'), 'utf8');\n\n// All suported function names\nconst allParts = Object.keys(new Runner({}).chain).filter(name => name !== 'test');\n\n// The output consists of the base declarations, the actual 'test' function declarations,\n// and the namespaced chainable methods.\nconst output = base + generatePrefixed([]);\n\nfs.writeFileSync(path.join(__dirname, 'generated.d.ts'), output);\n\n// Generates type definitions, for the specified prefix\n// The prefix is an array of function names\nfunction generatePrefixed(prefix) {\n\tlet output = '';\n\tlet children = '';\n\n\tfor (const part of allParts) {\n\t\tconst parts = prefix.concat([part]);\n\n\t\tif (prefix.indexOf(part) !== -1 || !verify(parts, true)) {\n\t\t\t// Function already in prefix or not allowed here\n\t\t\tcontinue;\n\t\t}\n\n\t\t// If `parts` is not sorted, we alias it to the sorted chain\n\t\tif (!isArraySorted(parts)) {\n\t\t\tif (exists(parts)) {\n\t\t\t\tparts.sort();\n\n\t\t\t\tlet chain;\n\t\t\t\tif (hasChildren(parts)) {\n\t\t\t\t\tchain = parts.join('_') + '<T>';\n\t\t\t\t} else {\n\t\t\t\t\t// This is a single function, not a namespace, so there's no type associated\n\t\t\t\t\t// and we need to dereference it as a property type\n\t\t\t\t\tconst last = parts.pop();\n\t\t\t\t\tconst joined = parts.join('_');\n\t\t\t\t\tchain = `${joined}<T>['${last}']`;\n\t\t\t\t}\n\n\t\t\t\toutput += `\\t${part}: Register_${chain};\\n`;\n\t\t\t}\n\n\t\t\tcontinue;\n\t\t}\n\n\t\t// Check that `part` is a valid function name.\n\t\t// `always` is a valid prefix, for instance of `always.after`,\n\t\t// but not a valid function name.\n\t\tif (verify(parts, false)) {\n\t\t\tif (arrayHas(parts)('todo')) {\n\t\t\t\t// 'todo' functions don't have a function argument, just a string\n\t\t\t\toutput += `\\t${part}: (name: string) => void;\\n`;\n\t\t\t} else {\n\t\t\t\tif (arrayHas(parts)('cb')) {\n\t\t\t\t\toutput += `\\t${part}: CallbackRegisterBase<T>`;\n\t\t\t\t} else {\n\t\t\t\t\toutput += `\\t${part}: RegisterBase<T>`;\n\t\t\t\t}\n\n\t\t\t\tif (hasChildren(parts)) {\n\t\t\t\t\t// This chain can be continued, make the property an intersection type with the chain continuation\n\t\t\t\t\tconst joined = parts.join('_');\n\t\t\t\t\toutput += ` & Register_${joined}<T>`;\n\t\t\t\t}\n\n\t\t\t\toutput += ';\\n';\n\t\t\t}\n\t\t}\n\n\t\tchildren += generatePrefixed(parts);\n\t}\n\n\tif (output === '') {\n\t\treturn children;\n\t}\n\n\tconst typeBody = `{\\n${output}}\\n${children}`;\n\n\tif (prefix.length === 0) {\n\t\t// No prefix, so this is the type for the default export\n\t\treturn `export interface Register<T> extends RegisterBase<T> ${typeBody}`;\n\t}\n\tconst namespace = ['Register'].concat(prefix).join('_');\n\treturn `interface ${namespace}<T> ${typeBody}`;\n}\n\n// Checks whether a chain is a valid function name (when `asPrefix === false`)\n// or a valid prefix that could contain members.\n// For instance, `test.always` is not a valid function name, but it is a valid\n// prefix of `test.always.after`.\nfunction verify(parts, asPrefix) {\n\tconst has = arrayHas(parts);\n\n\tif (has('only') + has('skip') + has('todo') > 1) {\n\t\treturn false;\n\t}\n\n\tconst beforeAfterCount = has('before') + has('beforeEach') + has('after') + has('afterEach');\n\n\tif (beforeAfterCount > 1) {\n\t\treturn false;\n\t}\n\n\tif (beforeAfterCount === 1) {\n\t\tif (has('only')) {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tif (has('always')) {\n\t\t// `always` can only be used with `after` or `afterEach`.\n\t\t// Without it can still be a valid prefix\n\t\tif (has('after') || has('afterEach')) {\n\t\t\treturn true;\n\t\t}\n\n\t\tif (!verify(parts.concat(['after']), false) && !verify(parts.concat(['afterEach']), false)) {\n\t\t\t// If `after` nor `afterEach` cannot be added to this prefix,\n\t\t\t// `always` is not allowed here.\n\t\t\treturn false;\n\t\t}\n\n\t\t// Only allowed as a prefix\n\t\treturn asPrefix;\n\t}\n\n\treturn true;\n}\n\n// Returns true if a chain can have any child properties\nfunction hasChildren(parts) {\n\t// Concatenate the chain with each other part, and see if any concatenations are valid functions\n\tconst validChildren = allParts\n\t\t.filter(newPart => parts.indexOf(newPart) === -1)\n\t\t.map(newPart => parts.concat([newPart]))\n\t\t.filter(longer => verify(longer, false));\n\n\treturn validChildren.length > 0;\n}\n\n// Checks whether a chain is a valid function name or a valid prefix with some member\nfunction exists(parts) {\n\tif (verify(parts, false)) {\n\t\t// Valid function name\n\t\treturn true;\n\t}\n\n\tif (!verify(parts, true)) {\n\t\t// Not valid prefix\n\t\treturn false;\n\t}\n\n\t// Valid prefix, check whether it has members\n\tfor (const prefix of allParts) {\n\t\tif (parts.indexOf(prefix) === -1 && exists(parts.concat([prefix]))) {\n\t\t\treturn true;\n\t\t}\n\t}\n\n\treturn false;\n}\n"}